{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7b9478",
   "metadata": {},
   "source": [
    "# Description: \n",
    "##### This script performs a standard machine learning workflow. For each of the 6 datasets, it first splits the data into a training set (80%) and a hold-out test set (20%).\n",
    "* It then runs a 5-fold cross-validation on the training set to find the best model.\n",
    "* Finally, it evaluates the best model on the hold-out test set to get the final performance score and saves this result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da93039",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "1. Make sure you have PyCaret and its dependencies installed.\n",
    "If not, uncomment the line below and run it once.\n",
    "> !pip install pycaret pandas\n",
    "\n",
    "2. Place this script in the same directory as your 90 CSV data files.\n",
    "\n",
    "3. Run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e18e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2746f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leechangmin/Desktop/Project/ETRI-Emotion/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8689c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_1_standard_cv_with_holdout():\n",
    "    \"\"\"\n",
    "    Runs the standard CV workflow with a hold-out test set.\n",
    "    \"\"\"\n",
    "    # --- Configuration ---\n",
    "    TARGET_COLUMN_NAME = 'label'\n",
    "    DATA_DIR = './data'\n",
    "    RESULT_DIR = './res'\n",
    "    GROUPS = ['Total', 'High', 'Low']\n",
    "    VARIABLES = ['arousal', 'valence']\n",
    "    \n",
    "    # Create the result directory if it doesn't exist\n",
    "    os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "\n",
    "    print(\"=====================================================================\")\n",
    "    print(\"===  STARTING EXPERIMENT 1: Standard CV with a Single Hold-Out  ===\")\n",
    "    print(\"=====================================================================\")\n",
    "\n",
    "    for group in GROUPS:\n",
    "        for variable in VARIABLES:\n",
    "            experiment_name = f\"{group}_{variable}\"\n",
    "            file_path = os.path.join(DATA_DIR, f\"{experiment_name}.csv\")\n",
    "            \n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"\\n--- Skipping {experiment_name}: File not found at {file_path} ---\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\n--- Processing: {experiment_name} ---\")\n",
    "            \n",
    "            # 1. Load the full dataset\n",
    "            full_dataset = pd.read_csv(file_path)\n",
    "            \n",
    "            # 2. Setup PyCaret environment.\n",
    "            # It will automatically split the data into 80% train and 20% test.\n",
    "            # The 5-fold CV will only be performed on the 80% training portion.\n",
    "            s = setup(data=full_dataset,\n",
    "                      target=TARGET_COLUMN_NAME,\n",
    "                      train_size=0.8,  # Use 80% for training, 20% is held out as test\n",
    "                      fold=5,          # Specify 5-fold cross-validation\n",
    "                      index=False,\n",
    "                      session_id=123,\n",
    "                      verbose=False)\n",
    "            \n",
    "            # 3. Compare models on the training set using 5-fold CV\n",
    "            print(\"  > Comparing models using 5-fold CV on the training set...\")\n",
    "            best_model = compare_models(verbose=False)\n",
    "            \n",
    "            # 4. Finalize the best model (retrain on the entire training set)\n",
    "            print(f\"  > Finalizing the best model: {pull().iloc[0,0]}\")\n",
    "            final_model = finalize_model(best_model)\n",
    "            \n",
    "            # 5. Evaluate the final model on the unseen hold-out test set (20%)\n",
    "            print(\"  > Evaluating the final model on the hold-out test set...\")\n",
    "            test_predictions = predict_model(final_model, data=s.X_test)\n",
    "            \n",
    "            # The performance metrics are on the last row of the output\n",
    "            test_metrics = test_predictions.iloc[-1:].copy()\n",
    "            test_metrics.drop('Model', axis=1, inplace=True)\n",
    "            test_metrics.index = [pull().iloc[0,0]] # Set index to the model name\n",
    "            \n",
    "            # 6. Save the test set performance to a CSV file\n",
    "            output_path = os.path.join(RESULT_DIR, f\"exp1_test_performance_{experiment_name}.csv\")\n",
    "            test_metrics.to_csv(output_path)\n",
    "            print(f\"  > Test performance saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf772b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    experiment_1_standard_cv_with_holdout()\n",
    "    print(\"\\n\\nExperiment 1 is complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da597e6",
   "metadata": {},
   "source": [
    "### Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e157c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_results():\n",
    "    \"\"\"\n",
    "    Read 'results_{group}_{variable}_classification_summary.csv' formatted files\n",
    "    and return a dictionary of DataFrames.\n",
    "    \"\"\"\n",
    "    # --- Configuration (can be adjusted as needed) ---\n",
    "    groups = ['Total', 'High', 'Low']\n",
    "    variables = ['arousal', 'valence']\n",
    "    \n",
    "    # dictionary to hold all results\n",
    "    all_results = {}\n",
    "    \n",
    "    print(\"Reading all result CSV files...\")\n",
    "\n",
    "    # Iterate through each group and variable to construct filenames\n",
    "    for group in groups:\n",
    "        for variable in variables:\n",
    "            # Construct the filename based on the group and variable\n",
    "            experiment_name = f\"{group}_{variable}\"\n",
    "            filename = f\"./res/results_{experiment_name}_classification_summary.csv\"\n",
    "            \n",
    "            try:\n",
    "                # CSV file into DataFrame\n",
    "                # index_col=0 to use the first column as index\n",
    "                df = pd.read_csv(filename, index_col=0)\n",
    "                \n",
    "                # Store the DataFrame in the dictionary with the experiment name as key\n",
    "                all_results[experiment_name] = df\n",
    "                print(f\"  - Successfully loaded: {filename}\")\n",
    "                \n",
    "            except FileNotFoundError:\n",
    "                print(f\"  - File not found, skipping: {filename}\")\n",
    "                \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    loaded_results = load_all_results()\n",
    "    print(\"\\n--- Summary of Loaded Results ---\")\n",
    "    \n",
    "    if not loaded_results:\n",
    "        print(\"No result files were found.\")\n",
    "    else:\n",
    "        # Display the top 5 models for each loaded result\n",
    "        for name, result_df in loaded_results.items():\n",
    "            print(f\"\\n--- Top 5 Models for [{name}] ---\")\n",
    "            print(result_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etri-emotion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
