{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7b9478",
   "metadata": {},
   "source": [
    "# Description: \n",
    "##### This script performs a 5-fold cross-validation experiment using PyCaret for a binary classification task. \n",
    "* It iterates through different data groups (Total, High, Low) and target variables (arousal, valence), aggregates the performance of various models across the predefined folds, and saves the summary results to CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da93039",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "1. Make sure you have PyCaret and its dependencies installed.\n",
    "If not, uncomment the line below and run it once.\n",
    "> !pip install pycaret pandas\n",
    "\n",
    "2. Place this script in the same directory as your 90 CSV data files.\n",
    "\n",
    "3. Run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e18e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycaret.classification import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2746f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leechangmin/Desktop/Project/ETRI-Emotion/src\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8689c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pycaret_classification_experiment():\n",
    "    \"\"\"\n",
    "    This function runs the main experiment. It sets up PyCaret for classification,\n",
    "    iterates through predefined data files for each fold, compares ML models,\n",
    "    and aggregates the results.\n",
    "    \"\"\"\n",
    "    # --- Configuration ---\n",
    "    # Set the target column name to 'label' based on the user's provided column list.\n",
    "    TARGET_COLUMN_NAME = 'label'\n",
    "\n",
    "    groups = ['Total', 'High', 'Low']\n",
    "    variables = ['arousal', 'valence'] # These are still used for file naming.\n",
    "    folds = range(1, 6)\n",
    "\n",
    "    final_results = {}\n",
    "\n",
    "    print(\"Starting PyCaret Classification Modeling...\")\n",
    "\n",
    "    for group in groups:\n",
    "        for variable in variables:\n",
    "            experiment_name = f\"{group}_{variable}\"\n",
    "            print(f\"\\n--- Starting Experiment: [{experiment_name}] ---\")\n",
    "\n",
    "            fold_results_list = []\n",
    "\n",
    "            for fold in folds:\n",
    "                try:\n",
    "                    train_file = f'./data/fold{fold}_{group}_{variable}_train.csv'\n",
    "                    valid_file = f'./data/fold{fold}_{group}_{variable}_valid.csv'\n",
    "                    test_file = f'./data/fold{fold}_{group}_{variable}_test.csv'\n",
    "\n",
    "                    if not all(os.path.exists(f) for f in [train_file, valid_file, test_file]):\n",
    "                        print(f\"  - Skipping Fold {fold}: Required CSV file(s) not found.\")\n",
    "                        continue\n",
    "\n",
    "                    train_df = pd.read_csv(train_file)\n",
    "                    valid_df = pd.read_csv(valid_file)\n",
    "                    test_df = pd.read_csv(test_file)\n",
    "\n",
    "                    train_valid_df = pd.concat([train_df, valid_df], ignore_index=True)\n",
    "\n",
    "                    print(f\"  - Fold {fold}: Training and evaluating models...\")\n",
    "\n",
    "                    # Initialize the PyCaret classification environment.\n",
    "                    s = setup(data=train_valid_df,\n",
    "                              test_data=test_df,\n",
    "                              # Using 'label' as the target column.\n",
    "                              target=TARGET_COLUMN_NAME,\n",
    "                              index=False,\n",
    "                              session_id=123,\n",
    "                              verbose=False)\n",
    "\n",
    "                    compare_models(verbose=False)\n",
    "                    results_grid = pull()\n",
    "                    fold_results_list.append(results_grid)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"  - An error occurred in Fold {fold}: {e}\")\n",
    "\n",
    "            if fold_results_list:\n",
    "                all_folds_df = pd.concat(fold_results_list)\n",
    "                mean_results = all_folds_df.groupby('Model').mean()\n",
    "                mean_results = mean_results.sort_values('Accuracy', ascending=False)\n",
    "                final_results[experiment_name] = mean_results\n",
    "                print(f\"  > Finished experiment [{experiment_name}]. Aggregated results from 5 folds.\")\n",
    "\n",
    "    if final_results:\n",
    "        print(\"\\n--- Final Aggregated Results for All Experiments ---\")\n",
    "        for name, result_df in final_results.items():\n",
    "            print(f\"\\n[{name}] - Top 5 Models by Average Accuracy\")\n",
    "            print(result_df.head())\n",
    "            output_filename = f'results_{name}_classification_summary.csv'\n",
    "            result_df.to_csv(output_filename)\n",
    "            print(f\"> Results saved to '{output_filename}'\")\n",
    "    else:\n",
    "        print(\"\\nNo results were processed. Please check your file names, paths, or for errors during execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf772b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PyCaret Classification Modeling...\n",
      "\n",
      "--- Starting Experiment: [Total_arousal] ---\n",
      "  - Fold 1: Training and evaluating models...\n",
      "  - Fold 2: Training and evaluating models...\n",
      "  - Fold 3: Training and evaluating models...\n",
      "  - Fold 4: Training and evaluating models...\n",
      "  - Fold 5: Training and evaluating models...\n",
      "  > Finished experiment [Total_arousal]. Aggregated results from 5 folds.\n",
      "\n",
      "--- Starting Experiment: [Total_valence] ---\n",
      "  - Fold 1: Training and evaluating models...\n",
      "  - Fold 2: Training and evaluating models...\n",
      "  - Fold 3: Training and evaluating models...\n",
      "  - Fold 4: Training and evaluating models...\n",
      "  - Fold 5: Training and evaluating models...\n",
      "  > Finished experiment [Total_valence]. Aggregated results from 5 folds.\n",
      "\n",
      "--- Starting Experiment: [High_arousal] ---\n",
      "  - Fold 1: Training and evaluating models...\n",
      "  - Fold 2: Training and evaluating models...\n",
      "  - Fold 3: Training and evaluating models...\n",
      "  - Fold 4: Training and evaluating models...\n",
      "  - Fold 5: Training and evaluating models...\n",
      "  > Finished experiment [High_arousal]. Aggregated results from 5 folds.\n",
      "\n",
      "--- Starting Experiment: [High_valence] ---\n",
      "  - Fold 1: Training and evaluating models...\n",
      "  - Fold 2: Training and evaluating models...\n",
      "  - Fold 3: Training and evaluating models...\n",
      "  - Fold 4: Training and evaluating models...\n",
      "  - Fold 5: Training and evaluating models...\n",
      "  > Finished experiment [High_valence]. Aggregated results from 5 folds.\n",
      "\n",
      "--- Starting Experiment: [Low_arousal] ---\n",
      "  - Fold 1: Training and evaluating models...\n",
      "  - Fold 2: Training and evaluating models...\n",
      "  - Fold 3: Training and evaluating models...\n",
      "  - Fold 4: Training and evaluating models...\n",
      "  - Fold 5: Training and evaluating models...\n",
      "  > Finished experiment [Low_arousal]. Aggregated results from 5 folds.\n",
      "\n",
      "--- Starting Experiment: [Low_valence] ---\n",
      "  - Fold 1: Training and evaluating models...\n",
      "  - Fold 2: Training and evaluating models...\n",
      "  - Fold 3: Training and evaluating models...\n",
      "  - Fold 4: Training and evaluating models...\n",
      "  - Fold 5: Training and evaluating models...\n",
      "  > Finished experiment [Low_valence]. Aggregated results from 5 folds.\n",
      "\n",
      "--- Final Aggregated Results for All Experiments ---\n",
      "\n",
      "[Total_arousal] - Top 5 Models by Average Accuracy\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "Gradient Boosting Classifier      0.95500  0.99220  0.95500  0.95646  0.95466   \n",
      "Random Forest Classifier          0.95374  0.99182  0.95374  0.95572  0.95346   \n",
      "CatBoost Classifier               0.95166  0.99230  0.95166  0.95406  0.95124   \n",
      "Ada Boost Classifier              0.94958  0.98554  0.94958  0.95152  0.94942   \n",
      "Light Gradient Boosting Machine   0.94958  0.99202  0.94958  0.95164  0.94924   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "Gradient Boosting Classifier     0.90404  0.90612    0.1682  \n",
      "Random Forest Classifier         0.90162  0.90414    0.0568  \n",
      "CatBoost Classifier              0.89680  0.89998    1.0144  \n",
      "Ada Boost Classifier             0.89340  0.89558    0.0422  \n",
      "Light Gradient Boosting Machine  0.89272  0.89540    0.3676  \n",
      "> Results saved to 'results_Total_arousal_classification_summary.csv'\n",
      "\n",
      "[Total_valence] - Top 5 Models by Average Accuracy\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "Random Forest Classifier          0.95792  0.99502  0.95792  0.96048  0.95784   \n",
      "CatBoost Classifier               0.95374  0.99478  0.95374  0.95686  0.95362   \n",
      "Extreme Gradient Boosting         0.95126  0.99274  0.95126  0.95346  0.95116   \n",
      "Gradient Boosting Classifier      0.95126  0.99380  0.95126  0.95390  0.95116   \n",
      "Light Gradient Boosting Machine   0.94918  0.99282  0.94918  0.95206  0.94906   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "Random Forest Classifier         0.91582  0.91836    0.0490  \n",
      "CatBoost Classifier              0.90748  0.91060    1.0770  \n",
      "Extreme Gradient Boosting        0.90250  0.90474    0.0182  \n",
      "Gradient Boosting Classifier     0.90250  0.90516    0.1742  \n",
      "Light Gradient Boosting Machine  0.89832  0.90122    0.3398  \n",
      "> Results saved to 'results_Total_valence_classification_summary.csv'\n",
      "\n",
      "[High_arousal] - Top 5 Models by Average Accuracy\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.93630  0.98786  0.93630  0.94044  0.93592   \n",
      "Light Gradient Boosting Machine   0.93354  0.98480  0.93354  0.93744  0.93324   \n",
      "Gradient Boosting Classifier      0.93072  0.98448  0.93072  0.93522  0.93038   \n",
      "Random Forest Classifier          0.92830  0.98466  0.92830  0.93282  0.92778   \n",
      "Extreme Gradient Boosting         0.92732  0.98296  0.92732  0.93184  0.92694   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "CatBoost Classifier              0.86818  0.87260    1.1244  \n",
      "Light Gradient Boosting Machine  0.86292  0.86686    0.2550  \n",
      "Gradient Boosting Classifier     0.85698  0.86158    0.0982  \n",
      "Random Forest Classifier         0.85150  0.85638    0.0418  \n",
      "Extreme Gradient Boosting        0.84988  0.85454    0.0218  \n",
      "> Results saved to 'results_High_arousal_classification_summary.csv'\n",
      "\n",
      "[High_valence] - Top 5 Models by Average Accuracy\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "Random Forest Classifier          0.93614  0.98898  0.93614  0.94076  0.93578   \n",
      "CatBoost Classifier               0.93442  0.98640  0.93442  0.93894  0.93400   \n",
      "Gradient Boosting Classifier      0.93194  0.98556  0.93194  0.93596  0.93160   \n",
      "Light Gradient Boosting Machine   0.92890  0.98548  0.92890  0.93294  0.92856   \n",
      "Ada Boost Classifier              0.92714  0.98000  0.92714  0.93228  0.92672   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "Random Forest Classifier         0.87210  0.87672    0.0464  \n",
      "CatBoost Classifier              0.86860  0.87312    1.0884  \n",
      "Gradient Boosting Classifier     0.86376  0.86774    0.1056  \n",
      "Light Gradient Boosting Machine  0.85768  0.86168    0.2542  \n",
      "Ada Boost Classifier             0.85418  0.85924    0.0314  \n",
      "> Results saved to 'results_High_valence_classification_summary.csv'\n",
      "\n",
      "[Low_arousal] - Top 5 Models by Average Accuracy\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "Gradient Boosting Classifier      0.95678  0.99182  0.95678  0.96176  0.95620   \n",
      "Light Gradient Boosting Machine   0.95630  0.99402  0.95630  0.96108  0.95558   \n",
      "Extreme Gradient Boosting         0.95484  0.99228  0.95484  0.95806  0.95438   \n",
      "Random Forest Classifier          0.95378  0.99246  0.95378  0.95916  0.95314   \n",
      "CatBoost Classifier               0.95254  0.99272  0.95254  0.95740  0.95172   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "Gradient Boosting Classifier     0.90680  0.91248    0.0814  \n",
      "Light Gradient Boosting Machine  0.90548  0.91122    0.2534  \n",
      "Extreme Gradient Boosting        0.90270  0.90660    0.0128  \n",
      "Random Forest Classifier         0.90068  0.90688    0.0396  \n",
      "CatBoost Classifier              0.89688  0.90302    0.9910  \n",
      "> Results saved to 'results_Low_arousal_classification_summary.csv'\n",
      "\n",
      "[Low_valence] - Top 5 Models by Average Accuracy\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.97120  0.99646  0.97120  0.97450  0.97102   \n",
      "Gradient Boosting Classifier      0.96888  0.99644  0.96888  0.97150  0.96870   \n",
      "Light Gradient Boosting Machine   0.96784  0.99592  0.96784  0.97122  0.96760   \n",
      "Random Forest Classifier          0.96780  0.99474  0.96780  0.97228  0.96746   \n",
      "Ada Boost Classifier              0.96588  0.99362  0.96588  0.96886  0.96570   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "CatBoost Classifier              0.94230  0.94562    1.1904  \n",
      "Gradient Boosting Classifier     0.93770  0.94032    0.0900  \n",
      "Light Gradient Boosting Machine  0.93554  0.93892    0.2756  \n",
      "Random Forest Classifier         0.93562  0.94000    0.0452  \n",
      "Ada Boost Classifier             0.93166  0.93466    0.0328  \n",
      "> Results saved to 'results_Low_valence_classification_summary.csv'\n"
     ]
    }
   ],
   "source": [
    "# This ensures the script runs when executed directly.\n",
    "if __name__ == '__main__':\n",
    "    run_pycaret_classification_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4ca820",
   "metadata": {},
   "source": [
    "### Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e157c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_results():\n",
    "    \"\"\"\n",
    "    Read 'results_{group}_{variable}_classification_summary.csv' formatted files\n",
    "    and return a dictionary of DataFrames.\n",
    "    \"\"\"\n",
    "    # --- Configuration (can be adjusted as needed) ---\n",
    "    groups = ['Total', 'High', 'Low']\n",
    "    variables = ['arousal', 'valence']\n",
    "    \n",
    "    # dictionary to hold all results\n",
    "    all_results = {}\n",
    "    \n",
    "    print(\"Reading all result CSV files...\")\n",
    "\n",
    "    # Iterate through each group and variable to construct filenames\n",
    "    for group in groups:\n",
    "        for variable in variables:\n",
    "            # Construct the filename based on the group and variable\n",
    "            experiment_name = f\"{group}_{variable}\"\n",
    "            filename = f\"./res/results_{experiment_name}_classification_summary.csv\"\n",
    "            \n",
    "            try:\n",
    "                # CSV file into DataFrame\n",
    "                # index_col=0 to use the first column as index\n",
    "                df = pd.read_csv(filename, index_col=0)\n",
    "                \n",
    "                # Store the DataFrame in the dictionary with the experiment name as key\n",
    "                all_results[experiment_name] = df\n",
    "                print(f\"  - Successfully loaded: {filename}\")\n",
    "                \n",
    "            except FileNotFoundError:\n",
    "                print(f\"  - File not found, skipping: {filename}\")\n",
    "                \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c281b40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all result CSV files...\n",
      "  - Successfully loaded: ./res/results_Total_arousal_classification_summary.csv\n",
      "  - Successfully loaded: ./res/results_Total_valence_classification_summary.csv\n",
      "  - Successfully loaded: ./res/results_High_arousal_classification_summary.csv\n",
      "  - Successfully loaded: ./res/results_High_valence_classification_summary.csv\n",
      "  - Successfully loaded: ./res/results_Low_arousal_classification_summary.csv\n",
      "  - Successfully loaded: ./res/results_Low_valence_classification_summary.csv\n",
      "\n",
      "--- Summary of Loaded Results ---\n",
      "\n",
      "--- Top 5 Models for [Total_arousal] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "Gradient Boosting Classifier      0.95500  0.99220  0.95500  0.95646  0.95466   \n",
      "Random Forest Classifier          0.95374  0.99182  0.95374  0.95572  0.95346   \n",
      "CatBoost Classifier               0.95166  0.99230  0.95166  0.95406  0.95124   \n",
      "Ada Boost Classifier              0.94958  0.98554  0.94958  0.95152  0.94942   \n",
      "Light Gradient Boosting Machine   0.94958  0.99202  0.94958  0.95164  0.94924   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "Gradient Boosting Classifier     0.90404  0.90612    0.1682  \n",
      "Random Forest Classifier         0.90162  0.90414    0.0568  \n",
      "CatBoost Classifier              0.89680  0.89998    1.0144  \n",
      "Ada Boost Classifier             0.89340  0.89558    0.0422  \n",
      "Light Gradient Boosting Machine  0.89272  0.89540    0.3676  \n",
      "\n",
      "--- Top 5 Models for [Total_valence] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "Random Forest Classifier          0.95792  0.99502  0.95792  0.96048  0.95784   \n",
      "CatBoost Classifier               0.95374  0.99478  0.95374  0.95686  0.95362   \n",
      "Extreme Gradient Boosting         0.95126  0.99274  0.95126  0.95346  0.95116   \n",
      "Gradient Boosting Classifier      0.95126  0.99380  0.95126  0.95390  0.95116   \n",
      "Light Gradient Boosting Machine   0.94918  0.99282  0.94918  0.95206  0.94906   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "Random Forest Classifier         0.91582  0.91836    0.0490  \n",
      "CatBoost Classifier              0.90748  0.91060    1.0770  \n",
      "Extreme Gradient Boosting        0.90250  0.90474    0.0182  \n",
      "Gradient Boosting Classifier     0.90250  0.90516    0.1742  \n",
      "Light Gradient Boosting Machine  0.89832  0.90122    0.3398  \n",
      "\n",
      "--- Top 5 Models for [High_arousal] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.93630  0.98786  0.93630  0.94044  0.93592   \n",
      "Light Gradient Boosting Machine   0.93354  0.98480  0.93354  0.93744  0.93324   \n",
      "Gradient Boosting Classifier      0.93072  0.98448  0.93072  0.93522  0.93038   \n",
      "Random Forest Classifier          0.92830  0.98466  0.92830  0.93282  0.92778   \n",
      "Extreme Gradient Boosting         0.92732  0.98296  0.92732  0.93184  0.92694   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "CatBoost Classifier              0.86818  0.87260    1.1244  \n",
      "Light Gradient Boosting Machine  0.86292  0.86686    0.2550  \n",
      "Gradient Boosting Classifier     0.85698  0.86158    0.0982  \n",
      "Random Forest Classifier         0.85150  0.85638    0.0418  \n",
      "Extreme Gradient Boosting        0.84988  0.85454    0.0218  \n",
      "\n",
      "--- Top 5 Models for [High_valence] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "Random Forest Classifier          0.93614  0.98898  0.93614  0.94076  0.93578   \n",
      "CatBoost Classifier               0.93442  0.98640  0.93442  0.93894  0.93400   \n",
      "Gradient Boosting Classifier      0.93194  0.98556  0.93194  0.93596  0.93160   \n",
      "Light Gradient Boosting Machine   0.92890  0.98548  0.92890  0.93294  0.92856   \n",
      "Ada Boost Classifier              0.92714  0.98000  0.92714  0.93228  0.92672   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "Random Forest Classifier         0.87210  0.87672    0.0464  \n",
      "CatBoost Classifier              0.86860  0.87312    1.0884  \n",
      "Gradient Boosting Classifier     0.86376  0.86774    0.1056  \n",
      "Light Gradient Boosting Machine  0.85768  0.86168    0.2542  \n",
      "Ada Boost Classifier             0.85418  0.85924    0.0314  \n",
      "\n",
      "--- Top 5 Models for [Low_arousal] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "Gradient Boosting Classifier      0.95678  0.99182  0.95678  0.96176  0.95620   \n",
      "Light Gradient Boosting Machine   0.95630  0.99402  0.95630  0.96108  0.95558   \n",
      "Extreme Gradient Boosting         0.95484  0.99228  0.95484  0.95806  0.95438   \n",
      "Random Forest Classifier          0.95378  0.99246  0.95378  0.95916  0.95314   \n",
      "CatBoost Classifier               0.95254  0.99272  0.95254  0.95740  0.95172   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "Gradient Boosting Classifier     0.90680  0.91248    0.0814  \n",
      "Light Gradient Boosting Machine  0.90548  0.91122    0.2534  \n",
      "Extreme Gradient Boosting        0.90270  0.90660    0.0128  \n",
      "Random Forest Classifier         0.90068  0.90688    0.0396  \n",
      "CatBoost Classifier              0.89688  0.90302    0.9910  \n",
      "\n",
      "--- Top 5 Models for [Low_valence] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.97120  0.99646  0.97120  0.97450  0.97102   \n",
      "Gradient Boosting Classifier      0.96888  0.99644  0.96888  0.97150  0.96870   \n",
      "Light Gradient Boosting Machine   0.96784  0.99592  0.96784  0.97122  0.96760   \n",
      "Random Forest Classifier          0.96780  0.99474  0.96780  0.97228  0.96746   \n",
      "Ada Boost Classifier              0.96588  0.99362  0.96588  0.96886  0.96570   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "CatBoost Classifier              0.94230  0.94562    1.1904  \n",
      "Gradient Boosting Classifier     0.93770  0.94032    0.0900  \n",
      "Light Gradient Boosting Machine  0.93554  0.93892    0.2756  \n",
      "Random Forest Classifier         0.93562  0.94000    0.0452  \n",
      "Ada Boost Classifier             0.93166  0.93466    0.0328  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    loaded_results = load_all_results()\n",
    "    print(\"\\n--- Summary of Loaded Results ---\")\n",
    "    \n",
    "    if not loaded_results:\n",
    "        print(\"No result files were found.\")\n",
    "    else:\n",
    "        # Display the top 5 models for each loaded result\n",
    "        for name, result_df in loaded_results.items():\n",
    "            print(f\"\\n--- Top 5 Models for [{name}] ---\")\n",
    "            print(result_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etri-emotion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
