{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7b9478",
   "metadata": {},
   "source": [
    "# Description: \n",
    "##### This script implements a robust, manually controlled 5-fold cross-validation.\n",
    "* For each of the 5 predefined folds, it performs the following steps:\n",
    "    1. Trains all models on `train.csv`.\n",
    "    2. Selects the best models based on performance on `valid.csv`.\n",
    "    3. Retrains EACH model on the combined `train.csv` + `valid.csv`.\n",
    "    4. Evaluates EACH retrained model on `test.csv` to get its test performance.\n",
    "    \n",
    "    Finally, it averages the test performance for each model type across all 5 folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da93039",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "1. Make sure you have PyCaret and its dependencies installed.\n",
    "If not, uncomment the line below and run it once.\n",
    "> !pip install pycaret pandas\n",
    "\n",
    "2. Place this script in the same directory as your 90 CSV data files.\n",
    "\n",
    "3. Run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e18e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycaret.classification import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2746f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leechangmin/Desktop/Project/ETRI-Emotion/cardio_exp1_given_data2\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8689c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_strict_manual_5_fold_experiment():\n",
    "    \"\"\"\n",
    "    This function runs the experiment with a strict, manual 5-fold\n",
    "    process that honors the predefined train, validation, and test files.\n",
    "    \"\"\"\n",
    "    # --- Configuration ---\n",
    "    TARGET_COLUMN_NAME = 'label'\n",
    "    GROUPS = ['Total', 'High', 'Low']\n",
    "    VARIABLES = ['arousal', 'valence']\n",
    "    FOLDS = range(1, 6)\n",
    "    \n",
    "    final_averaged_results = {}\n",
    "\n",
    "    print(\"Starting PyCaret Classification with Manual 5-Fold Cross-Validation...\")\n",
    "\n",
    "    for group in GROUPS:\n",
    "        for variable in VARIABLES:\n",
    "            experiment_name = f\"{group}_{variable}\"\n",
    "            print(f\"\\n--- Starting Experiment: [{experiment_name}] ---\")\n",
    "\n",
    "            # This list will store the test performance DataFrames from each of the 5 folds.\n",
    "            all_folds_test_performance = []\n",
    "\n",
    "            for fold in FOLDS:\n",
    "                try:\n",
    "                    print(f\"  - Processing Fold {fold}...\")\n",
    "                    # 1. Load the strictly separated datasets\n",
    "                    train_df = pd.read_csv(f'./data/fold{fold}_{group}_{variable}_train.csv')\n",
    "                    valid_df = pd.read_csv(f'./data/fold{fold}_{group}_{variable}_valid.csv')\n",
    "                    test_df = pd.read_csv(f'./data/fold{fold}_{group}_{variable}_test.csv')\n",
    "\n",
    "                    # 2. Setup PyCaret to train on `train_df` and use `valid_df` as the hold-out\n",
    "                    #    set for initial model ranking.\n",
    "                    s = setup(data=train_df,\n",
    "                              test_data=valid_df,\n",
    "                              target=TARGET_COLUMN_NAME,\n",
    "                              index=False,\n",
    "                              session_id=123,\n",
    "                              verbose=False)\n",
    "\n",
    "                    # 3. Compare all models to get a performance grid on the validation set.\n",
    "                    compare_models(verbose=False)\n",
    "                    validation_grid = pull() # This contains all model types and their valid scores.\n",
    "\n",
    "                    # This list will store the test results for ALL models within THIS fold.\n",
    "                    current_fold_test_results = []\n",
    "                    \n",
    "                    # 4. Iterate through every model type, finalize it, and evaluate on the test set.\n",
    "                    print(f\"    > Evaluating all models on Fold {fold} test set...\")\n",
    "                    for model_id in validation_grid.index:\n",
    "                        # Create the model instance trained on train_df\n",
    "                        model = create_model(model_id, verbose=False)\n",
    "                        # Retrain on combined train_df + valid_df\n",
    "                        final_model = finalize_model(model)\n",
    "                        # Predict on the unseen test_df\n",
    "                        test_predictions = predict_model(final_model, data=test_df, verbose=False)\n",
    "                        # Extract and store the test metrics\n",
    "                        test_metrics = pull()\n",
    "                        # Manually add the 'Model' column since the metrics row doesn't have it.\n",
    "                        test_metrics['Model'] = validation_grid.loc[model_id, 'Model']\n",
    "                        \n",
    "                        current_fold_test_results.append(test_metrics)\n",
    "                    \n",
    "                    # Combine all model results for the current fold and add to the main list\n",
    "                    all_folds_test_performance.append(pd.concat(current_fold_test_results))\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"  - An error occurred in Fold {fold}: {e}\")\n",
    "\n",
    "            # After all 5 folds are processed, average the results\n",
    "            if all_folds_test_performance:\n",
    "                # Combine the performance DataFrames from all 5 folds\n",
    "                full_results_df = pd.concat(all_folds_test_performance)\n",
    "                \n",
    "                # Calculate the mean test performance for each model type across the 5 folds\n",
    "                numeric_cols = full_results_df.select_dtypes(include='number').columns\n",
    "                average_results = full_results_df.groupby('Model')[numeric_cols].mean().sort_values('Accuracy', ascending=False)\n",
    "                \n",
    "                final_averaged_results[experiment_name] = average_results\n",
    "                print(f\"  > Finished experiment [{experiment_name}]. Averaged test results from 5 folds.\")\n",
    "\n",
    "    # --- Print and Save Final Averaged Results ---\n",
    "    if final_averaged_results:\n",
    "        print(\"\\n--- Final Averaged Test Performance Across All Experiments ---\")\n",
    "        for name, result_df in final_averaged_results.items():\n",
    "            print(f\"\\n[{name}] - Top 5 Models by Averaged Test Performance:\")\n",
    "            print(result_df.head())\n",
    "            output_filename = f'./res/results_{name}_manual_5fold_summary.csv'\n",
    "            result_df.to_csv(output_filename)\n",
    "            print(f\"> Results saved to '{output_filename}'\")\n",
    "    else:\n",
    "        print(\"\\nNo results were processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf772b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PyCaret Classification with Manual 5-Fold Cross-Validation...\n",
      "\n",
      "--- Starting Experiment: [Total_arousal] ---\n",
      "  - Processing Fold 1...\n",
      "    > Evaluating all models on Fold 1 test set...\n",
      "  - Processing Fold 2...\n",
      "    > Evaluating all models on Fold 2 test set...\n",
      "  - Processing Fold 3...\n",
      "    > Evaluating all models on Fold 3 test set...\n",
      "  - Processing Fold 4...\n",
      "    > Evaluating all models on Fold 4 test set...\n",
      "  - Processing Fold 5...\n",
      "    > Evaluating all models on Fold 5 test set...\n",
      "  > Finished experiment [Total_arousal]. Averaged test results from 5 folds.\n",
      "\n",
      "--- Starting Experiment: [Total_valence] ---\n",
      "  - Processing Fold 1...\n",
      "    > Evaluating all models on Fold 1 test set...\n",
      "  - Processing Fold 2...\n",
      "    > Evaluating all models on Fold 2 test set...\n",
      "  - Processing Fold 3...\n",
      "    > Evaluating all models on Fold 3 test set...\n",
      "  - Processing Fold 4...\n",
      "    > Evaluating all models on Fold 4 test set...\n",
      "  - Processing Fold 5...\n",
      "    > Evaluating all models on Fold 5 test set...\n",
      "  > Finished experiment [Total_valence]. Averaged test results from 5 folds.\n",
      "\n",
      "--- Starting Experiment: [High_arousal] ---\n",
      "  - Processing Fold 1...\n",
      "    > Evaluating all models on Fold 1 test set...\n",
      "  - Processing Fold 2...\n",
      "    > Evaluating all models on Fold 2 test set...\n",
      "  - Processing Fold 3...\n",
      "    > Evaluating all models on Fold 3 test set...\n",
      "  - Processing Fold 4...\n",
      "    > Evaluating all models on Fold 4 test set...\n",
      "  - Processing Fold 5...\n",
      "    > Evaluating all models on Fold 5 test set...\n",
      "  > Finished experiment [High_arousal]. Averaged test results from 5 folds.\n",
      "\n",
      "--- Starting Experiment: [High_valence] ---\n",
      "  - Processing Fold 1...\n",
      "    > Evaluating all models on Fold 1 test set...\n",
      "  - Processing Fold 2...\n",
      "    > Evaluating all models on Fold 2 test set...\n",
      "  - Processing Fold 3...\n",
      "    > Evaluating all models on Fold 3 test set...\n",
      "  - Processing Fold 4...\n",
      "    > Evaluating all models on Fold 4 test set...\n",
      "  - Processing Fold 5...\n",
      "    > Evaluating all models on Fold 5 test set...\n",
      "  > Finished experiment [High_valence]. Averaged test results from 5 folds.\n",
      "\n",
      "--- Starting Experiment: [Low_arousal] ---\n",
      "  - Processing Fold 1...\n",
      "    > Evaluating all models on Fold 1 test set...\n",
      "  - Processing Fold 2...\n",
      "    > Evaluating all models on Fold 2 test set...\n",
      "  - Processing Fold 3...\n",
      "    > Evaluating all models on Fold 3 test set...\n",
      "  - Processing Fold 4...\n",
      "    > Evaluating all models on Fold 4 test set...\n",
      "  - Processing Fold 5...\n",
      "    > Evaluating all models on Fold 5 test set...\n",
      "  > Finished experiment [Low_arousal]. Averaged test results from 5 folds.\n",
      "\n",
      "--- Starting Experiment: [Low_valence] ---\n",
      "  - Processing Fold 1...\n",
      "    > Evaluating all models on Fold 1 test set...\n",
      "  - Processing Fold 2...\n",
      "    > Evaluating all models on Fold 2 test set...\n",
      "  - Processing Fold 3...\n",
      "    > Evaluating all models on Fold 3 test set...\n",
      "  - Processing Fold 4...\n",
      "    > Evaluating all models on Fold 4 test set...\n",
      "  - Processing Fold 5...\n",
      "    > Evaluating all models on Fold 5 test set...\n",
      "  > Finished experiment [Low_valence]. Averaged test results from 5 folds.\n",
      "\n",
      "--- Final Averaged Test Performance Across All Experiments ---\n",
      "\n",
      "[Total_arousal] - Top 5 Models by Averaged Test Performance:\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "Light Gradient Boosting Machine   0.99584  0.99982  0.99584  0.99592  0.99584   \n",
      "Random Forest Classifier          0.99584  1.00000  0.99584  0.99592  0.99584   \n",
      "Ada Boost Classifier              0.99376  0.99902  0.99376  0.99398  0.99376   \n",
      "CatBoost Classifier               0.99168  1.00000  0.99168  0.99194  0.99168   \n",
      "Gradient Boosting Classifier      0.98960  1.00000  0.98960  0.99008  0.98960   \n",
      "\n",
      "                                   Kappa      MCC  \n",
      "Model                                              \n",
      "Light Gradient Boosting Machine  0.99152  0.99160  \n",
      "Random Forest Classifier         0.99154  0.99162  \n",
      "Ada Boost Classifier             0.98734  0.98754  \n",
      "CatBoost Classifier              0.98310  0.98334  \n",
      "Gradient Boosting Classifier     0.97892  0.97938  \n",
      "> Results saved to 'results_Total_arousal_manual_5fold_summary.csv'\n",
      "\n",
      "[Total_valence] - Top 5 Models by Averaged Test Performance:\n",
      "                           Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                     \n",
      "Decision Tree Classifier    0.99168  0.99154  0.99168  0.99176  0.99168   \n",
      "Random Forest Classifier    0.98544  0.99960  0.98544  0.98600  0.98544   \n",
      "Extreme Gradient Boosting   0.98542  0.99744  0.98542  0.98628  0.98546   \n",
      "Ada Boost Classifier        0.98334  0.99498  0.98334  0.98458  0.98338   \n",
      "CatBoost Classifier         0.98334  0.99938  0.98334  0.98424  0.98338   \n",
      "\n",
      "                             Kappa      MCC  \n",
      "Model                                        \n",
      "Decision Tree Classifier   0.98310  0.98318  \n",
      "Random Forest Classifier   0.97044  0.97098  \n",
      "Extreme Gradient Boosting  0.97052  0.97130  \n",
      "Ada Boost Classifier       0.96640  0.96750  \n",
      "CatBoost Classifier        0.96628  0.96710  \n",
      "> Results saved to 'results_Total_valence_manual_5fold_summary.csv'\n",
      "\n",
      "[High_arousal] - Top 5 Models by Averaged Test Performance:\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.98960  0.99976  0.98960  0.98980  0.98960   \n",
      "Light Gradient Boosting Machine   0.98960  0.99886  0.98960  0.98972  0.98960   \n",
      "Random Forest Classifier          0.98752  0.99930  0.98752  0.98768  0.98752   \n",
      "Extreme Gradient Boosting         0.98544  0.99920  0.98544  0.98570  0.98542   \n",
      "Gradient Boosting Classifier      0.98544  0.99886  0.98544  0.98562  0.98542   \n",
      "\n",
      "                                   Kappa      MCC  \n",
      "Model                                              \n",
      "CatBoost Classifier              0.97888  0.97908  \n",
      "Light Gradient Boosting Machine  0.97888  0.97900  \n",
      "Random Forest Classifier         0.97466  0.97482  \n",
      "Extreme Gradient Boosting        0.97038  0.97068  \n",
      "Gradient Boosting Classifier     0.97036  0.97058  \n",
      "> Results saved to 'results_High_arousal_manual_5fold_summary.csv'\n",
      "\n",
      "[High_valence] - Top 5 Models by Averaged Test Performance:\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.99792  0.99964  0.99792  0.99796  0.99792   \n",
      "Gradient Boosting Classifier      0.99584  0.99956  0.99584  0.99592  0.99584   \n",
      "Random Forest Classifier          0.99584  1.00000  0.99584  0.99598  0.99582   \n",
      "Light Gradient Boosting Machine   0.99376  0.99940  0.99376  0.99394  0.99374   \n",
      "Ada Boost Classifier              0.99168  0.99876  0.99168  0.99174  0.99166   \n",
      "\n",
      "                                   Kappa      MCC  \n",
      "Model                                              \n",
      "CatBoost Classifier              0.99576  0.99580  \n",
      "Gradient Boosting Classifier     0.99152  0.99160  \n",
      "Random Forest Classifier         0.99148  0.99166  \n",
      "Light Gradient Boosting Machine  0.98724  0.98746  \n",
      "Ada Boost Classifier             0.98302  0.98312  \n",
      "> Results saved to 'results_High_valence_manual_5fold_summary.csv'\n",
      "\n",
      "[Low_arousal] - Top 5 Models by Averaged Test Performance:\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.99376  0.99744  0.99376  0.99394  0.99374   \n",
      "Light Gradient Boosting Machine   0.99376  0.99798  0.99376  0.99394  0.99374   \n",
      "Gradient Boosting Classifier      0.99168  0.99604  0.99168  0.99196  0.99164   \n",
      "Random Forest Classifier          0.99168  0.99678  0.99168  0.99204  0.99164   \n",
      "Ada Boost Classifier              0.98960  0.99648  0.98960  0.98992  0.98956   \n",
      "\n",
      "                                   Kappa      MCC  \n",
      "Model                                              \n",
      "CatBoost Classifier              0.98724  0.98746  \n",
      "Light Gradient Boosting Machine  0.98724  0.98746  \n",
      "Gradient Boosting Classifier     0.98296  0.98332  \n",
      "Random Forest Classifier         0.98296  0.98338  \n",
      "Ada Boost Classifier             0.97872  0.97912  \n",
      "> Results saved to 'results_Low_arousal_manual_5fold_summary.csv'\n",
      "\n",
      "[Low_valence] - Top 5 Models by Averaged Test Performance:\n",
      "                              Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                        \n",
      "Decision Tree Classifier       0.98958  0.98968  0.98958  0.98966  0.98960   \n",
      "Gradient Boosting Classifier   0.98752  0.99912  0.98752  0.98796  0.98748   \n",
      "Extreme Gradient Boosting      0.98750  0.99894  0.98750  0.98816  0.98744   \n",
      "CatBoost Classifier            0.98544  0.99930  0.98544  0.98592  0.98540   \n",
      "Random Forest Classifier       0.98542  0.99872  0.98542  0.98566  0.98540   \n",
      "\n",
      "                                Kappa      MCC  \n",
      "Model                                           \n",
      "Decision Tree Classifier      0.97890  0.97894  \n",
      "Gradient Boosting Classifier  0.97448  0.97498  \n",
      "Extreme Gradient Boosting     0.97440  0.97516  \n",
      "CatBoost Classifier           0.97024  0.97078  \n",
      "Random Forest Classifier      0.97026  0.97054  \n",
      "> Results saved to 'results_Low_valence_manual_5fold_summary.csv'\n"
     ]
    }
   ],
   "source": [
    "# This ensures the script runs when executed directly.\n",
    "if __name__ == '__main__':\n",
    "    run_strict_manual_5_fold_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4ca820",
   "metadata": {},
   "source": [
    "### Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e157c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_results():\n",
    "    \"\"\"\n",
    "    Read 'results_{group}_{variable}_classification_summary.csv' formatted files\n",
    "    and return a dictionary of DataFrames.\n",
    "    \"\"\"\n",
    "    # --- Configuration (can be adjusted as needed) ---\n",
    "    groups = ['Total', 'High', 'Low']\n",
    "    variables = ['arousal', 'valence']\n",
    "    \n",
    "    # dictionary to hold all results\n",
    "    all_results = {}\n",
    "    \n",
    "    print(\"Reading all result CSV files...\")\n",
    "\n",
    "    # Iterate through each group and variable to construct filenames\n",
    "    for group in groups:\n",
    "        for variable in variables:\n",
    "            # Construct the filename based on the group and variable\n",
    "            experiment_name = f\"{group}_{variable}\"\n",
    "            filename = f\"./res/results_{experiment_name}_manual_5fold_summary.csv\"\n",
    "            \n",
    "            try:\n",
    "                # CSV file into DataFrame\n",
    "                # index_col=0 to use the first column as index\n",
    "                df = pd.read_csv(filename, index_col=0)\n",
    "                \n",
    "                # Store the DataFrame in the dictionary with the experiment name as key\n",
    "                all_results[experiment_name] = df\n",
    "                print(f\"  - Successfully loaded: {filename}\")\n",
    "                \n",
    "            except FileNotFoundError:\n",
    "                print(f\"  - File not found, skipping: {filename}\")\n",
    "                \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c281b40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all result CSV files...\n",
      "  - Successfully loaded: ./res/results_Total_arousal_manual_5fold_summary.csv\n",
      "  - Successfully loaded: ./res/results_Total_valence_manual_5fold_summary.csv\n",
      "  - Successfully loaded: ./res/results_High_arousal_manual_5fold_summary.csv\n",
      "  - Successfully loaded: ./res/results_High_valence_manual_5fold_summary.csv\n",
      "  - Successfully loaded: ./res/results_Low_arousal_manual_5fold_summary.csv\n",
      "  - Successfully loaded: ./res/results_Low_valence_manual_5fold_summary.csv\n",
      "\n",
      "--- Summary of Loaded Results ---\n",
      "\n",
      "--- Top 5 Models for [Total_arousal] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "Light Gradient Boosting Machine   0.99584  0.99982  0.99584  0.99592  0.99584   \n",
      "Random Forest Classifier          0.99584  1.00000  0.99584  0.99592  0.99584   \n",
      "Ada Boost Classifier              0.99376  0.99902  0.99376  0.99398  0.99376   \n",
      "CatBoost Classifier               0.99168  1.00000  0.99168  0.99194  0.99168   \n",
      "Gradient Boosting Classifier      0.98960  1.00000  0.98960  0.99008  0.98960   \n",
      "\n",
      "                                   Kappa      MCC  \n",
      "Model                                              \n",
      "Light Gradient Boosting Machine  0.99152  0.99160  \n",
      "Random Forest Classifier         0.99154  0.99162  \n",
      "Ada Boost Classifier             0.98734  0.98754  \n",
      "CatBoost Classifier              0.98310  0.98334  \n",
      "Gradient Boosting Classifier     0.97892  0.97938  \n",
      "\n",
      "--- Top 5 Models for [Total_valence] ---\n",
      "                           Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                     \n",
      "Decision Tree Classifier    0.99168  0.99154  0.99168  0.99176  0.99168   \n",
      "Random Forest Classifier    0.98544  0.99960  0.98544  0.98600  0.98544   \n",
      "Extreme Gradient Boosting   0.98542  0.99744  0.98542  0.98628  0.98546   \n",
      "Ada Boost Classifier        0.98334  0.99498  0.98334  0.98458  0.98338   \n",
      "CatBoost Classifier         0.98334  0.99938  0.98334  0.98424  0.98338   \n",
      "\n",
      "                             Kappa      MCC  \n",
      "Model                                        \n",
      "Decision Tree Classifier   0.98310  0.98318  \n",
      "Random Forest Classifier   0.97044  0.97098  \n",
      "Extreme Gradient Boosting  0.97052  0.97130  \n",
      "Ada Boost Classifier       0.96640  0.96750  \n",
      "CatBoost Classifier        0.96628  0.96710  \n",
      "\n",
      "--- Top 5 Models for [High_arousal] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.98960  0.99976  0.98960  0.98980  0.98960   \n",
      "Light Gradient Boosting Machine   0.98960  0.99886  0.98960  0.98972  0.98960   \n",
      "Random Forest Classifier          0.98752  0.99930  0.98752  0.98768  0.98752   \n",
      "Extreme Gradient Boosting         0.98544  0.99920  0.98544  0.98570  0.98542   \n",
      "Gradient Boosting Classifier      0.98544  0.99886  0.98544  0.98562  0.98542   \n",
      "\n",
      "                                   Kappa      MCC  \n",
      "Model                                              \n",
      "CatBoost Classifier              0.97888  0.97908  \n",
      "Light Gradient Boosting Machine  0.97888  0.97900  \n",
      "Random Forest Classifier         0.97466  0.97482  \n",
      "Extreme Gradient Boosting        0.97038  0.97068  \n",
      "Gradient Boosting Classifier     0.97036  0.97058  \n",
      "\n",
      "--- Top 5 Models for [High_valence] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.99792  0.99964  0.99792  0.99796  0.99792   \n",
      "Gradient Boosting Classifier      0.99584  0.99956  0.99584  0.99592  0.99584   \n",
      "Random Forest Classifier          0.99584  1.00000  0.99584  0.99598  0.99582   \n",
      "Light Gradient Boosting Machine   0.99376  0.99940  0.99376  0.99394  0.99374   \n",
      "Ada Boost Classifier              0.99168  0.99876  0.99168  0.99174  0.99166   \n",
      "\n",
      "                                   Kappa      MCC  \n",
      "Model                                              \n",
      "CatBoost Classifier              0.99576  0.99580  \n",
      "Gradient Boosting Classifier     0.99152  0.99160  \n",
      "Random Forest Classifier         0.99148  0.99166  \n",
      "Light Gradient Boosting Machine  0.98724  0.98746  \n",
      "Ada Boost Classifier             0.98302  0.98312  \n",
      "\n",
      "--- Top 5 Models for [Low_arousal] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.99376  0.99744  0.99376  0.99394  0.99374   \n",
      "Light Gradient Boosting Machine   0.99376  0.99798  0.99376  0.99394  0.99374   \n",
      "Gradient Boosting Classifier      0.99168  0.99604  0.99168  0.99196  0.99164   \n",
      "Random Forest Classifier          0.99168  0.99678  0.99168  0.99204  0.99164   \n",
      "Ada Boost Classifier              0.98960  0.99648  0.98960  0.98992  0.98956   \n",
      "\n",
      "                                   Kappa      MCC  \n",
      "Model                                              \n",
      "CatBoost Classifier              0.98724  0.98746  \n",
      "Light Gradient Boosting Machine  0.98724  0.98746  \n",
      "Gradient Boosting Classifier     0.98296  0.98332  \n",
      "Random Forest Classifier         0.98296  0.98338  \n",
      "Ada Boost Classifier             0.97872  0.97912  \n",
      "\n",
      "--- Top 5 Models for [Low_valence] ---\n",
      "                              Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                        \n",
      "Decision Tree Classifier       0.98958  0.98968  0.98958  0.98966  0.98960   \n",
      "Gradient Boosting Classifier   0.98752  0.99912  0.98752  0.98796  0.98748   \n",
      "Extreme Gradient Boosting      0.98750  0.99894  0.98750  0.98816  0.98744   \n",
      "CatBoost Classifier            0.98544  0.99930  0.98544  0.98592  0.98540   \n",
      "Random Forest Classifier       0.98542  0.99872  0.98542  0.98566  0.98540   \n",
      "\n",
      "                                Kappa      MCC  \n",
      "Model                                           \n",
      "Decision Tree Classifier      0.97890  0.97894  \n",
      "Gradient Boosting Classifier  0.97448  0.97498  \n",
      "Extreme Gradient Boosting     0.97440  0.97516  \n",
      "CatBoost Classifier           0.97024  0.97078  \n",
      "Random Forest Classifier      0.97026  0.97054  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    loaded_results = load_all_results()\n",
    "    print(\"\\n--- Summary of Loaded Results ---\")\n",
    "    \n",
    "    if not loaded_results:\n",
    "        print(\"No result files were found.\")\n",
    "    else:\n",
    "        # Display the top 5 models for each loaded result\n",
    "        for name, result_df in loaded_results.items():\n",
    "            print(f\"\\n--- Top 5 Models for [{name}] ---\")\n",
    "            print(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94794762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all result CSV files...\n",
      "  - Successfully loaded: ./res/results_Total_arousal_manual_5fold_summary.csv\n",
      "  - Successfully loaded: ./res/results_Total_valence_manual_5fold_summary.csv\n",
      "  - Successfully loaded: ./res/results_High_arousal_manual_5fold_summary.csv\n",
      "  - Successfully loaded: ./res/results_High_valence_manual_5fold_summary.csv\n",
      "  - Successfully loaded: ./res/results_Low_arousal_manual_5fold_summary.csv\n",
      "  - Successfully loaded: ./res/results_Low_valence_manual_5fold_summary.csv\n",
      "\n",
      "==================================================\n",
      "      <<< Summary of All Loaded Results >>>\n",
      "==================================================\n",
      "\n",
      "\n",
      "--- Performance Results for [Total_arousal] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1    Kappa      MCC\n",
      "Model                                                                                          \n",
      "Light Gradient Boosting Machine   0.99584  0.99982  0.99584  0.99592  0.99584  0.99152  0.99160\n",
      "Random Forest Classifier          0.99584  1.00000  0.99584  0.99592  0.99584  0.99154  0.99162\n",
      "Ada Boost Classifier              0.99376  0.99902  0.99376  0.99398  0.99376  0.98734  0.98754\n",
      "CatBoost Classifier               0.99168  1.00000  0.99168  0.99194  0.99168  0.98310  0.98334\n",
      "Gradient Boosting Classifier      0.98960  1.00000  0.98960  0.99008  0.98960  0.97892  0.97938\n",
      "Extra Trees Classifier            0.98544  0.99828  0.98544  0.98590  0.98538  0.97020  0.97078\n",
      "Decision Tree Classifier          0.98334  0.98412  0.98334  0.98390  0.98338  0.96632  0.96680\n",
      "Extreme Gradient Boosting         0.97918  0.99764  0.97918  0.97954  0.97914  0.95754  0.95798\n",
      "SVM - Linear Kernel               0.62710  0.61082  0.62710  0.63424  0.60982  0.22528  0.24024\n",
      "Quadratic Discriminant Analysis   0.58748  0.64840  0.58748  0.63606  0.55014  0.15744  0.19304\n",
      "Naive Bayes                       0.57084  0.62478  0.57084  0.49180  0.48122  0.11482  0.12524\n",
      "Dummy Classifier                  0.56250  0.50000  0.56250  0.31640  0.40500  0.00000  0.00000\n",
      "K Neighbors Classifier            0.55622  0.59452  0.55622  0.54536  0.54368  0.07234  0.07426\n",
      "Linear Discriminant Analysis      0.55418  0.62664  0.55418  0.42444  0.41794 -0.01062 -0.03096\n",
      "Logistic Regression               0.55002  0.62064  0.55002  0.39388  0.40942 -0.02122 -0.05656\n",
      "Ridge Classifier                  0.55002  0.49048  0.55002  0.39388  0.40942 -0.02122 -0.05656\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "--- Performance Results for [Total_valence] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1    Kappa      MCC\n",
      "Model                                                                                          \n",
      "Decision Tree Classifier          0.99168  0.99154  0.99168  0.99176  0.99168  0.98310  0.98318\n",
      "Random Forest Classifier          0.98544  0.99960  0.98544  0.98600  0.98544  0.97044  0.97098\n",
      "Extreme Gradient Boosting         0.98542  0.99744  0.98542  0.98628  0.98546  0.97052  0.97130\n",
      "Ada Boost Classifier              0.98334  0.99498  0.98334  0.98458  0.98338  0.96640  0.96750\n",
      "CatBoost Classifier               0.98334  0.99938  0.98334  0.98424  0.98338  0.96628  0.96710\n",
      "Light Gradient Boosting Machine   0.98334  0.99858  0.98334  0.98458  0.98338  0.96640  0.96750\n",
      "Gradient Boosting Classifier      0.98126  0.99902  0.98126  0.98254  0.98130  0.96216  0.96330\n",
      "Extra Trees Classifier            0.97084  0.99276  0.97084  0.97256  0.97092  0.94138  0.94278\n",
      "Dummy Classifier                  0.56250  0.50000  0.56250  0.31640  0.40500  0.00000  0.00000\n",
      "K Neighbors Classifier            0.55624  0.56810  0.55624  0.57456  0.55548  0.12670  0.13106\n",
      "Linear Discriminant Analysis      0.55002  0.54444  0.55002  0.55720  0.54980  0.10202  0.10118\n",
      "SVM - Linear Kernel               0.55000  0.55766  0.55000  0.57976  0.53696  0.11016  0.12674\n",
      "Ridge Classifier                  0.53750  0.53864  0.53750  0.54494  0.53680  0.07820  0.07684\n",
      "Logistic Regression               0.53542  0.53882  0.53542  0.54364  0.53464  0.07652  0.07472\n",
      "Quadratic Discriminant Analysis   0.52292  0.56998  0.52292  0.60526  0.47650  0.09234  0.11608\n",
      "Naive Bayes                       0.51668  0.61306  0.51668  0.52326  0.43658  0.03758  0.04190\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "--- Performance Results for [High_arousal] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1    Kappa      MCC\n",
      "Model                                                                                          \n",
      "CatBoost Classifier               0.98960  0.99976  0.98960  0.98980  0.98960  0.97888  0.97908\n",
      "Light Gradient Boosting Machine   0.98960  0.99886  0.98960  0.98972  0.98960  0.97888  0.97900\n",
      "Random Forest Classifier          0.98752  0.99930  0.98752  0.98768  0.98752  0.97466  0.97482\n",
      "Extreme Gradient Boosting         0.98544  0.99920  0.98544  0.98570  0.98542  0.97038  0.97068\n",
      "Gradient Boosting Classifier      0.98544  0.99886  0.98544  0.98562  0.98542  0.97036  0.97058\n",
      "Ada Boost Classifier              0.98336  0.99894  0.98336  0.98350  0.98334  0.96614  0.96632\n",
      "Extra Trees Classifier            0.98126  0.99898  0.98126  0.98156  0.98126  0.96190  0.96220\n",
      "Decision Tree Classifier          0.94584  0.94446  0.94584  0.94684  0.94576  0.88974  0.89086\n",
      "Naive Bayes                       0.61250  0.74772  0.61250  0.59790  0.56162  0.24316  0.27406\n",
      "K Neighbors Classifier            0.59792  0.61748  0.59792  0.59366  0.58870  0.16462  0.16944\n",
      "Logistic Regression               0.58748  0.58510  0.58748  0.58016  0.55608  0.11792  0.13126\n",
      "Dummy Classifier                  0.56250  0.50000  0.56250  0.31640  0.40500  0.00000  0.00000\n",
      "Quadratic Discriminant Analysis   0.56250  0.50000  0.56250  0.31640  0.40500  0.00000  0.00000\n",
      "Linear Discriminant Analysis      0.50622  0.53104  0.50622  0.49722  0.49132 -0.02182 -0.02164\n",
      "Ridge Classifier                  0.50622  0.48440  0.50622  0.49632  0.48566 -0.02990 -0.02692\n",
      "SVM - Linear Kernel               0.49582  0.47724  0.49582  0.48750  0.48366 -0.04604 -0.04382\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "--- Performance Results for [High_valence] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1    Kappa      MCC\n",
      "Model                                                                                          \n",
      "CatBoost Classifier               0.99792  0.99964  0.99792  0.99796  0.99792  0.99576  0.99580\n",
      "Gradient Boosting Classifier      0.99584  0.99956  0.99584  0.99592  0.99584  0.99152  0.99160\n",
      "Random Forest Classifier          0.99584  1.00000  0.99584  0.99598  0.99582  0.99148  0.99166\n",
      "Light Gradient Boosting Machine   0.99376  0.99940  0.99376  0.99394  0.99374  0.98724  0.98746\n",
      "Ada Boost Classifier              0.99168  0.99876  0.99168  0.99174  0.99166  0.98302  0.98312\n",
      "Extreme Gradient Boosting         0.98960  0.99896  0.98960  0.98986  0.98958  0.97878  0.97908\n",
      "Decision Tree Classifier          0.97292  0.96906  0.97292  0.97630  0.97240  0.94380  0.94776\n",
      "Extra Trees Classifier            0.95626  0.99306  0.95626  0.96000  0.95574  0.91004  0.91434\n",
      "Ridge Classifier                  0.59586  0.58890  0.59586  0.60270  0.58296  0.18168  0.18716\n",
      "Logistic Regression               0.59378  0.59930  0.59378  0.59854  0.58184  0.17300  0.17854\n",
      "Linear Discriminant Analysis      0.58544  0.57972  0.58544  0.59204  0.57132  0.16106  0.16606\n",
      "Naive Bayes                       0.57498  0.72418  0.57498  0.66168  0.52152  0.15834  0.19342\n",
      "Dummy Classifier                  0.56250  0.50000  0.56250  0.31640  0.40500  0.00000  0.00000\n",
      "K Neighbors Classifier            0.54792  0.60372  0.54792  0.56140  0.54674  0.10408  0.10636\n",
      "SVM - Linear Kernel               0.54164  0.52168  0.54164  0.44902  0.46790  0.04542 -0.00366\n",
      "Quadratic Discriminant Analysis   0.46250  0.50000  0.46250  0.21640  0.29404  0.00000  0.00000\n",
      "-----------------------------------------------\n",
      "\n",
      "\n",
      "--- Performance Results for [Low_arousal] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1    Kappa      MCC\n",
      "Model                                                                                          \n",
      "CatBoost Classifier               0.99376  0.99744  0.99376  0.99394  0.99374  0.98724  0.98746\n",
      "Light Gradient Boosting Machine   0.99376  0.99798  0.99376  0.99394  0.99374  0.98724  0.98746\n",
      "Gradient Boosting Classifier      0.99168  0.99604  0.99168  0.99196  0.99164  0.98296  0.98332\n",
      "Random Forest Classifier          0.99168  0.99678  0.99168  0.99204  0.99164  0.98296  0.98338\n",
      "Ada Boost Classifier              0.98960  0.99648  0.98960  0.98992  0.98956  0.97872  0.97912\n",
      "Extreme Gradient Boosting         0.98960  0.99798  0.98960  0.99006  0.98954  0.97868  0.97924\n",
      "Decision Tree Classifier          0.98750  0.98730  0.98750  0.98750  0.98750  0.97460  0.97460\n",
      "Extra Trees Classifier            0.93336  0.96848  0.93336  0.93358  0.93266  0.86266  0.86384\n",
      "Linear Discriminant Analysis      0.60210  0.64816  0.60210  0.61916  0.56358  0.15412  0.18648\n",
      "Ridge Classifier                  0.59582  0.56138  0.59582  0.61856  0.54720  0.13260  0.17212\n",
      "Dummy Classifier                  0.56250  0.50000  0.56250  0.31640  0.40500  0.00000  0.00000\n",
      "Logistic Regression               0.56250  0.63388  0.56250  0.56876  0.50054  0.04898  0.08114\n",
      "Quadratic Discriminant Analysis   0.56250  0.50000  0.56250  0.31640  0.40500  0.00000  0.00000\n",
      "SVM - Linear Kernel               0.51872  0.48438  0.51872  0.48984  0.46366 -0.03016 -0.02992\n",
      "K Neighbors Classifier            0.51456  0.52242  0.51456  0.48878  0.48618 -0.03170 -0.03498\n",
      "Naive Bayes                       0.45002  0.55528  0.45002  0.37368  0.29818  0.01780  0.04488\n",
      "----------------------------------------------\n",
      "\n",
      "\n",
      "--- Performance Results for [Low_valence] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1    Kappa      MCC\n",
      "Model                                                                                          \n",
      "Decision Tree Classifier          0.98958  0.98968  0.98958  0.98966  0.98960  0.97890  0.97894\n",
      "Gradient Boosting Classifier      0.98752  0.99912  0.98752  0.98796  0.98748  0.97448  0.97498\n",
      "Extreme Gradient Boosting         0.98750  0.99894  0.98750  0.98816  0.98744  0.97440  0.97516\n",
      "CatBoost Classifier               0.98544  0.99930  0.98544  0.98592  0.98540  0.97024  0.97078\n",
      "Random Forest Classifier          0.98542  0.99872  0.98542  0.98566  0.98540  0.97026  0.97054\n",
      "Light Gradient Boosting Machine   0.98334  0.99886  0.98334  0.98348  0.98332  0.96606  0.96622\n",
      "Extra Trees Classifier            0.98126  0.99504  0.98126  0.98144  0.98124  0.96182  0.96202\n",
      "Ada Boost Classifier              0.97500  0.99674  0.97500  0.97512  0.97498  0.94908  0.94924\n",
      "Naive Bayes                       0.55002  0.59648  0.55002  0.66672  0.45518  0.07554  0.13094\n",
      "K Neighbors Classifier            0.52500  0.57934  0.52500  0.54944  0.51878  0.07642  0.08036\n",
      "Linear Discriminant Analysis      0.52290  0.55788  0.52290  0.53926  0.51874  0.06562  0.06488\n",
      "Ridge Classifier                  0.51874  0.52884  0.51874  0.53408  0.51442  0.05768  0.05572\n",
      "Logistic Regression               0.50626  0.57936  0.50626  0.52212  0.50150  0.03444  0.03202\n",
      "SVM - Linear Kernel               0.47500  0.49524  0.47500  0.51712  0.45196 -0.01116  0.00078\n",
      "Dummy Classifier                  0.46250  0.50000  0.46250  0.21640  0.29404  0.00000  0.00000\n",
      "Quadratic Discriminant Analysis   0.46250  0.50000  0.46250  0.21640  0.29404  0.00000  0.00000\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Pandas display options to prevent truncation\n",
    "# Set options to display all rows and columns without truncation\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000) # Adjust width to prevent line wrapping\n",
    "\n",
    "def load_all_results():\n",
    "    \"\"\"\n",
    "    Read 'results_{group}_{variable}_manual_5fold_summary.csv' formatted files\n",
    "    and return a dictionary of DataFrames.\n",
    "    \"\"\"\n",
    "    # --- Configuration (can be adjusted as needed) ---\n",
    "    groups = ['Total', 'High', 'Low']\n",
    "    variables = ['arousal', 'valence']\n",
    "    \n",
    "    # dictionary to hold all results\n",
    "    all_results = {}\n",
    "    \n",
    "    print(\"Reading all result CSV files...\")\n",
    "\n",
    "    # Iterate through each group and variable to construct filenames\n",
    "    for group in groups:\n",
    "        for variable in variables:\n",
    "            # Construct the filename based on the group and variable\n",
    "            experiment_name = f\"{group}_{variable}\"\n",
    "            filename = f\"./res/results_{experiment_name}_manual_5fold_summary.csv\"\n",
    "            \n",
    "            try:\n",
    "                # CSV file into DataFrame\n",
    "                # index_col=0 to use the first column as index\n",
    "                df = pd.read_csv(filename, index_col='Model') # Use 'Model' column as index\n",
    "                \n",
    "                # Store the DataFrame in the dictionary with the experiment name as key\n",
    "                all_results[experiment_name] = df\n",
    "                print(f\"  - Successfully loaded: {filename}\")\n",
    "                \n",
    "            except FileNotFoundError:\n",
    "                print(f\"  - File not found, skipping: {filename}\")\n",
    "                \n",
    "    return all_results\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Run the function to load all result data\n",
    "    loaded_results = load_all_results()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"      <<< Summary of All Loaded Results >>>\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    if not loaded_results:\n",
    "        print(\"No result files were found.\")\n",
    "    else:\n",
    "        # Loop through and print each result DataFrame\n",
    "        for name, result_df in loaded_results.items():\n",
    "            print(f\"\\n\\n--- Performance Results for [{name}] ---\")\n",
    "            # Using print() on a DataFrame with the options set will display it fully\n",
    "            print(result_df)\n",
    "            print(\"-\"*(len(name) + 35))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etri-emotion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
