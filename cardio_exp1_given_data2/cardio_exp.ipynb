{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7b9478",
   "metadata": {},
   "source": [
    "# Description: \n",
    "##### This script implements a robust, manually controlled 5-fold cross-validation.\n",
    "* For each of the 5 predefined folds, it performs the following steps:\n",
    "    1. Trains all models on `train.csv`.\n",
    "    2. Selects the best models based on performance on `valid.csv`.\n",
    "    3. Retrains EACH model on the combined `train.csv` + `valid.csv`.\n",
    "    4. Evaluates EACH retrained model on `test.csv` to get its test performance.\n",
    "    \n",
    "    Finally, it averages the test performance for each model type across all 5 folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da93039",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "1. Make sure you have PyCaret and its dependencies installed.\n",
    "If not, uncomment the line below and run it once.\n",
    "> !pip install pycaret pandas\n",
    "\n",
    "2. Place this script in the same directory as your 90 CSV data files.\n",
    "\n",
    "3. Run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e18e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycaret.classification import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2746f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leechangmin/Desktop/Project/ETRI-Emotion/cardio_exp1_given_data2\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8689c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_strict_manual_5_fold_experiment():\n",
    "    \"\"\"\n",
    "    This function runs the experiment with a strict, manual 5-fold\n",
    "    process that honors the predefined train, validation, and test files.\n",
    "    \"\"\"\n",
    "    # --- Configuration ---\n",
    "    TARGET_COLUMN_NAME = 'label'\n",
    "    GROUPS = ['Total', 'High', 'Low']\n",
    "    VARIABLES = ['arousal', 'valence']\n",
    "    FOLDS = range(1, 6)\n",
    "    \n",
    "    final_averaged_results = {}\n",
    "\n",
    "    print(\"Starting PyCaret Classification with Manual 5-Fold Cross-Validation...\")\n",
    "\n",
    "    for group in GROUPS:\n",
    "        for variable in VARIABLES:\n",
    "            experiment_name = f\"{group}_{variable}\"\n",
    "            print(f\"\\n--- Starting Experiment: [{experiment_name}] ---\")\n",
    "\n",
    "            # This list will store the test performance DataFrames from each of the 5 folds.\n",
    "            all_folds_test_performance = []\n",
    "\n",
    "            for fold in FOLDS:\n",
    "                try:\n",
    "                    print(f\"  - Processing Fold {fold}...\")\n",
    "                    # 1. Load the strictly separated datasets\n",
    "                    train_df = pd.read_csv(f'./data/fold{fold}_{group}_{variable}_train.csv')\n",
    "                    valid_df = pd.read_csv(f'./data/fold{fold}_{group}_{variable}_valid.csv')\n",
    "                    test_df = pd.read_csv(f'./data/fold{fold}_{group}_{variable}_test.csv')\n",
    "\n",
    "                    # 2. Setup PyCaret to train on `train_df` and use `valid_df` as the hold-out\n",
    "                    #    set for initial model ranking.\n",
    "                    s = setup(data=train_df,\n",
    "                              test_data=valid_df,\n",
    "                              target=TARGET_COLUMN_NAME,\n",
    "                              index=False,\n",
    "                              session_id=123,\n",
    "                              verbose=False)\n",
    "\n",
    "                    # 3. Compare all models to get a performance grid on the validation set.\n",
    "                    compare_models(verbose=False)\n",
    "                    validation_grid = pull() # This contains all model types and their valid scores.\n",
    "\n",
    "                    # This list will store the test results for ALL models within THIS fold.\n",
    "                    current_fold_test_results = []\n",
    "                    \n",
    "                    # 4. Iterate through every model type, finalize it, and evaluate on the test set.\n",
    "                    print(f\"    > Evaluating all models on Fold {fold} test set...\")\n",
    "                    for model_id in validation_grid.index:\n",
    "                        # Create the model instance trained on train_df\n",
    "                        model = create_model(model_id, verbose=False)\n",
    "                        # Retrain on combined train_df + valid_df\n",
    "                        final_model = finalize_model(model)\n",
    "                        # Predict on the unseen test_df\n",
    "                        test_predictions = predict_model(final_model, data=test_df, verbose=False)\n",
    "                        # Extract and store the test metrics\n",
    "                        test_metrics = pull()\n",
    "                        # Manually add the 'Model' column since the metrics row doesn't have it.\n",
    "                        test_metrics['Model'] = validation_grid.loc[model_id, 'Model']\n",
    "                        \n",
    "                        current_fold_test_results.append(test_metrics)\n",
    "                    \n",
    "                    # Combine all model results for the current fold and add to the main list\n",
    "                    all_folds_test_performance.append(pd.concat(current_fold_test_results))\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"  - An error occurred in Fold {fold}: {e}\")\n",
    "\n",
    "            # After all 5 folds are processed, average the results\n",
    "            if all_folds_test_performance:\n",
    "                # Combine the performance DataFrames from all 5 folds\n",
    "                full_results_df = pd.concat(all_folds_test_performance)\n",
    "                \n",
    "                # Calculate the mean test performance for each model type across the 5 folds\n",
    "                numeric_cols = full_results_df.select_dtypes(include='number').columns\n",
    "                average_results = full_results_df.groupby('Model')[numeric_cols].mean().sort_values('Accuracy', ascending=False)\n",
    "                \n",
    "                final_averaged_results[experiment_name] = average_results\n",
    "                print(f\"  > Finished experiment [{experiment_name}]. Averaged test results from 5 folds.\")\n",
    "\n",
    "    # --- Print and Save Final Averaged Results ---\n",
    "    if final_averaged_results:\n",
    "        print(\"\\n--- Final Averaged Test Performance Across All Experiments ---\")\n",
    "        for name, result_df in final_averaged_results.items():\n",
    "            print(f\"\\n[{name}] - Top 5 Models by Averaged Test Performance:\")\n",
    "            print(result_df.head())\n",
    "            output_filename = f'./res/results_{name}_manual_5fold_summary.csv'\n",
    "            result_df.to_csv(output_filename)\n",
    "            print(f\"> Results saved to '{output_filename}'\")\n",
    "    else:\n",
    "        print(\"\\nNo results were processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf772b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PyCaret Classification with Manual 5-Fold Cross-Validation...\n",
      "\n",
      "--- Starting Experiment: [Total_arousal] ---\n",
      "  - Processing Fold 1...\n",
      "    > Evaluating all models on Fold 1 test set...\n",
      "  - Processing Fold 2...\n",
      "    > Evaluating all models on Fold 2 test set...\n",
      "  - Processing Fold 3...\n",
      "    > Evaluating all models on Fold 3 test set...\n",
      "  - Processing Fold 4...\n",
      "    > Evaluating all models on Fold 4 test set...\n",
      "  - Processing Fold 5...\n",
      "    > Evaluating all models on Fold 5 test set...\n",
      "  > Finished experiment [Total_arousal]. Averaged test results from 5 folds.\n",
      "\n",
      "--- Starting Experiment: [Total_valence] ---\n",
      "  - Processing Fold 1...\n",
      "    > Evaluating all models on Fold 1 test set...\n",
      "  - Processing Fold 2...\n",
      "    > Evaluating all models on Fold 2 test set...\n",
      "  - Processing Fold 3...\n",
      "    > Evaluating all models on Fold 3 test set...\n",
      "  - Processing Fold 4...\n",
      "    > Evaluating all models on Fold 4 test set...\n",
      "  - Processing Fold 5...\n",
      "    > Evaluating all models on Fold 5 test set...\n",
      "  > Finished experiment [Total_valence]. Averaged test results from 5 folds.\n",
      "\n",
      "--- Starting Experiment: [High_arousal] ---\n",
      "  - Processing Fold 1...\n",
      "    > Evaluating all models on Fold 1 test set...\n",
      "  - Processing Fold 2...\n",
      "    > Evaluating all models on Fold 2 test set...\n",
      "  - Processing Fold 3...\n",
      "    > Evaluating all models on Fold 3 test set...\n",
      "  - Processing Fold 4...\n",
      "    > Evaluating all models on Fold 4 test set...\n",
      "  - Processing Fold 5...\n",
      "    > Evaluating all models on Fold 5 test set...\n",
      "  > Finished experiment [High_arousal]. Averaged test results from 5 folds.\n",
      "\n",
      "--- Starting Experiment: [High_valence] ---\n",
      "  - Processing Fold 1...\n",
      "    > Evaluating all models on Fold 1 test set...\n",
      "  - Processing Fold 2...\n",
      "    > Evaluating all models on Fold 2 test set...\n",
      "  - Processing Fold 3...\n",
      "    > Evaluating all models on Fold 3 test set...\n",
      "  - Processing Fold 4...\n",
      "    > Evaluating all models on Fold 4 test set...\n",
      "  - Processing Fold 5...\n",
      "    > Evaluating all models on Fold 5 test set...\n",
      "  > Finished experiment [High_valence]. Averaged test results from 5 folds.\n",
      "\n",
      "--- Starting Experiment: [Low_arousal] ---\n",
      "  - Processing Fold 1...\n",
      "    > Evaluating all models on Fold 1 test set...\n",
      "  - Processing Fold 2...\n",
      "    > Evaluating all models on Fold 2 test set...\n",
      "  - Processing Fold 3...\n",
      "    > Evaluating all models on Fold 3 test set...\n",
      "  - Processing Fold 4...\n",
      "    > Evaluating all models on Fold 4 test set...\n",
      "  - Processing Fold 5...\n",
      "    > Evaluating all models on Fold 5 test set...\n",
      "  > Finished experiment [Low_arousal]. Averaged test results from 5 folds.\n",
      "\n",
      "--- Starting Experiment: [Low_valence] ---\n",
      "  - Processing Fold 1...\n",
      "    > Evaluating all models on Fold 1 test set...\n",
      "  - Processing Fold 2...\n",
      "    > Evaluating all models on Fold 2 test set...\n",
      "  - Processing Fold 3...\n",
      "    > Evaluating all models on Fold 3 test set...\n",
      "  - Processing Fold 4...\n",
      "    > Evaluating all models on Fold 4 test set...\n",
      "  - Processing Fold 5...\n",
      "    > Evaluating all models on Fold 5 test set...\n",
      "  > Finished experiment [Low_valence]. Averaged test results from 5 folds.\n",
      "\n",
      "--- Final Averaged Test Performance Across All Experiments ---\n",
      "\n",
      "[Total_arousal] - Top 5 Models by Averaged Test Performance:\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "Light Gradient Boosting Machine   0.99584  0.99982  0.99584  0.99592  0.99584   \n",
      "Random Forest Classifier          0.99584  1.00000  0.99584  0.99592  0.99584   \n",
      "Ada Boost Classifier              0.99376  0.99902  0.99376  0.99398  0.99376   \n",
      "CatBoost Classifier               0.99168  1.00000  0.99168  0.99194  0.99168   \n",
      "Gradient Boosting Classifier      0.98960  1.00000  0.98960  0.99008  0.98960   \n",
      "\n",
      "                                   Kappa      MCC  \n",
      "Model                                              \n",
      "Light Gradient Boosting Machine  0.99152  0.99160  \n",
      "Random Forest Classifier         0.99154  0.99162  \n",
      "Ada Boost Classifier             0.98734  0.98754  \n",
      "CatBoost Classifier              0.98310  0.98334  \n",
      "Gradient Boosting Classifier     0.97892  0.97938  \n",
      "> Results saved to 'results_Total_arousal_manual_5fold_summary.csv'\n",
      "\n",
      "[Total_valence] - Top 5 Models by Averaged Test Performance:\n",
      "                           Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                     \n",
      "Decision Tree Classifier    0.99168  0.99154  0.99168  0.99176  0.99168   \n",
      "Random Forest Classifier    0.98544  0.99960  0.98544  0.98600  0.98544   \n",
      "Extreme Gradient Boosting   0.98542  0.99744  0.98542  0.98628  0.98546   \n",
      "Ada Boost Classifier        0.98334  0.99498  0.98334  0.98458  0.98338   \n",
      "CatBoost Classifier         0.98334  0.99938  0.98334  0.98424  0.98338   \n",
      "\n",
      "                             Kappa      MCC  \n",
      "Model                                        \n",
      "Decision Tree Classifier   0.98310  0.98318  \n",
      "Random Forest Classifier   0.97044  0.97098  \n",
      "Extreme Gradient Boosting  0.97052  0.97130  \n",
      "Ada Boost Classifier       0.96640  0.96750  \n",
      "CatBoost Classifier        0.96628  0.96710  \n",
      "> Results saved to 'results_Total_valence_manual_5fold_summary.csv'\n",
      "\n",
      "[High_arousal] - Top 5 Models by Averaged Test Performance:\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.98960  0.99976  0.98960  0.98980  0.98960   \n",
      "Light Gradient Boosting Machine   0.98960  0.99886  0.98960  0.98972  0.98960   \n",
      "Random Forest Classifier          0.98752  0.99930  0.98752  0.98768  0.98752   \n",
      "Extreme Gradient Boosting         0.98544  0.99920  0.98544  0.98570  0.98542   \n",
      "Gradient Boosting Classifier      0.98544  0.99886  0.98544  0.98562  0.98542   \n",
      "\n",
      "                                   Kappa      MCC  \n",
      "Model                                              \n",
      "CatBoost Classifier              0.97888  0.97908  \n",
      "Light Gradient Boosting Machine  0.97888  0.97900  \n",
      "Random Forest Classifier         0.97466  0.97482  \n",
      "Extreme Gradient Boosting        0.97038  0.97068  \n",
      "Gradient Boosting Classifier     0.97036  0.97058  \n",
      "> Results saved to 'results_High_arousal_manual_5fold_summary.csv'\n",
      "\n",
      "[High_valence] - Top 5 Models by Averaged Test Performance:\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.99792  0.99964  0.99792  0.99796  0.99792   \n",
      "Gradient Boosting Classifier      0.99584  0.99956  0.99584  0.99592  0.99584   \n",
      "Random Forest Classifier          0.99584  1.00000  0.99584  0.99598  0.99582   \n",
      "Light Gradient Boosting Machine   0.99376  0.99940  0.99376  0.99394  0.99374   \n",
      "Ada Boost Classifier              0.99168  0.99876  0.99168  0.99174  0.99166   \n",
      "\n",
      "                                   Kappa      MCC  \n",
      "Model                                              \n",
      "CatBoost Classifier              0.99576  0.99580  \n",
      "Gradient Boosting Classifier     0.99152  0.99160  \n",
      "Random Forest Classifier         0.99148  0.99166  \n",
      "Light Gradient Boosting Machine  0.98724  0.98746  \n",
      "Ada Boost Classifier             0.98302  0.98312  \n",
      "> Results saved to 'results_High_valence_manual_5fold_summary.csv'\n",
      "\n",
      "[Low_arousal] - Top 5 Models by Averaged Test Performance:\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.99376  0.99744  0.99376  0.99394  0.99374   \n",
      "Light Gradient Boosting Machine   0.99376  0.99798  0.99376  0.99394  0.99374   \n",
      "Gradient Boosting Classifier      0.99168  0.99604  0.99168  0.99196  0.99164   \n",
      "Random Forest Classifier          0.99168  0.99678  0.99168  0.99204  0.99164   \n",
      "Ada Boost Classifier              0.98960  0.99648  0.98960  0.98992  0.98956   \n",
      "\n",
      "                                   Kappa      MCC  \n",
      "Model                                              \n",
      "CatBoost Classifier              0.98724  0.98746  \n",
      "Light Gradient Boosting Machine  0.98724  0.98746  \n",
      "Gradient Boosting Classifier     0.98296  0.98332  \n",
      "Random Forest Classifier         0.98296  0.98338  \n",
      "Ada Boost Classifier             0.97872  0.97912  \n",
      "> Results saved to 'results_Low_arousal_manual_5fold_summary.csv'\n",
      "\n",
      "[Low_valence] - Top 5 Models by Averaged Test Performance:\n",
      "                              Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                        \n",
      "Decision Tree Classifier       0.98958  0.98968  0.98958  0.98966  0.98960   \n",
      "Gradient Boosting Classifier   0.98752  0.99912  0.98752  0.98796  0.98748   \n",
      "Extreme Gradient Boosting      0.98750  0.99894  0.98750  0.98816  0.98744   \n",
      "CatBoost Classifier            0.98544  0.99930  0.98544  0.98592  0.98540   \n",
      "Random Forest Classifier       0.98542  0.99872  0.98542  0.98566  0.98540   \n",
      "\n",
      "                                Kappa      MCC  \n",
      "Model                                           \n",
      "Decision Tree Classifier      0.97890  0.97894  \n",
      "Gradient Boosting Classifier  0.97448  0.97498  \n",
      "Extreme Gradient Boosting     0.97440  0.97516  \n",
      "CatBoost Classifier           0.97024  0.97078  \n",
      "Random Forest Classifier      0.97026  0.97054  \n",
      "> Results saved to 'results_Low_valence_manual_5fold_summary.csv'\n"
     ]
    }
   ],
   "source": [
    "# This ensures the script runs when executed directly.\n",
    "if __name__ == '__main__':\n",
    "    run_strict_manual_5_fold_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4ca820",
   "metadata": {},
   "source": [
    "### Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e157c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_results():\n",
    "    \"\"\"\n",
    "    Read 'results_{group}_{variable}_classification_summary.csv' formatted files\n",
    "    and return a dictionary of DataFrames.\n",
    "    \"\"\"\n",
    "    # --- Configuration (can be adjusted as needed) ---\n",
    "    groups = ['Total', 'High', 'Low']\n",
    "    variables = ['arousal', 'valence']\n",
    "    \n",
    "    # dictionary to hold all results\n",
    "    all_results = {}\n",
    "    \n",
    "    print(\"Reading all result CSV files...\")\n",
    "\n",
    "    # Iterate through each group and variable to construct filenames\n",
    "    for group in groups:\n",
    "        for variable in variables:\n",
    "            # Construct the filename based on the group and variable\n",
    "            experiment_name = f\"{group}_{variable}\"\n",
    "            filename = f\"./res/results_{experiment_name}_manual_5fold_summary.csv\"\n",
    "            \n",
    "            try:\n",
    "                # CSV file into DataFrame\n",
    "                # index_col=0 to use the first column as index\n",
    "                df = pd.read_csv(filename, index_col=0)\n",
    "                \n",
    "                # Store the DataFrame in the dictionary with the experiment name as key\n",
    "                all_results[experiment_name] = df\n",
    "                print(f\"  - Successfully loaded: {filename}\")\n",
    "                \n",
    "            except FileNotFoundError:\n",
    "                print(f\"  - File not found, skipping: {filename}\")\n",
    "                \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c281b40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all result CSV files...\n",
      "  - Successfully loaded: ./res/results_Total_arousal_manual_5fold_summary.csv\n",
      "  - Successfully loaded: ./res/results_Total_valence_manual_5fold_summary.csv\n",
      "  - Successfully loaded: ./res/results_High_arousal_manual_5fold_summary.csv\n",
      "  - Successfully loaded: ./res/results_High_valence_manual_5fold_summary.csv\n",
      "  - Successfully loaded: ./res/results_Low_arousal_manual_5fold_summary.csv\n",
      "  - Successfully loaded: ./res/results_Low_valence_manual_5fold_summary.csv\n",
      "\n",
      "--- Summary of Loaded Results ---\n",
      "\n",
      "--- Top 5 Models for [Total_arousal] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "Light Gradient Boosting Machine   0.99584  0.99982  0.99584  0.99592  0.99584   \n",
      "Random Forest Classifier          0.99584  1.00000  0.99584  0.99592  0.99584   \n",
      "Ada Boost Classifier              0.99376  0.99902  0.99376  0.99398  0.99376   \n",
      "CatBoost Classifier               0.99168  1.00000  0.99168  0.99194  0.99168   \n",
      "Gradient Boosting Classifier      0.98960  1.00000  0.98960  0.99008  0.98960   \n",
      "\n",
      "                                   Kappa      MCC  \n",
      "Model                                              \n",
      "Light Gradient Boosting Machine  0.99152  0.99160  \n",
      "Random Forest Classifier         0.99154  0.99162  \n",
      "Ada Boost Classifier             0.98734  0.98754  \n",
      "CatBoost Classifier              0.98310  0.98334  \n",
      "Gradient Boosting Classifier     0.97892  0.97938  \n",
      "\n",
      "--- Top 5 Models for [Total_valence] ---\n",
      "                           Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                     \n",
      "Decision Tree Classifier    0.99168  0.99154  0.99168  0.99176  0.99168   \n",
      "Random Forest Classifier    0.98544  0.99960  0.98544  0.98600  0.98544   \n",
      "Extreme Gradient Boosting   0.98542  0.99744  0.98542  0.98628  0.98546   \n",
      "Ada Boost Classifier        0.98334  0.99498  0.98334  0.98458  0.98338   \n",
      "CatBoost Classifier         0.98334  0.99938  0.98334  0.98424  0.98338   \n",
      "\n",
      "                             Kappa      MCC  \n",
      "Model                                        \n",
      "Decision Tree Classifier   0.98310  0.98318  \n",
      "Random Forest Classifier   0.97044  0.97098  \n",
      "Extreme Gradient Boosting  0.97052  0.97130  \n",
      "Ada Boost Classifier       0.96640  0.96750  \n",
      "CatBoost Classifier        0.96628  0.96710  \n",
      "\n",
      "--- Top 5 Models for [High_arousal] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.98960  0.99976  0.98960  0.98980  0.98960   \n",
      "Light Gradient Boosting Machine   0.98960  0.99886  0.98960  0.98972  0.98960   \n",
      "Random Forest Classifier          0.98752  0.99930  0.98752  0.98768  0.98752   \n",
      "Extreme Gradient Boosting         0.98544  0.99920  0.98544  0.98570  0.98542   \n",
      "Gradient Boosting Classifier      0.98544  0.99886  0.98544  0.98562  0.98542   \n",
      "\n",
      "                                   Kappa      MCC  \n",
      "Model                                              \n",
      "CatBoost Classifier              0.97888  0.97908  \n",
      "Light Gradient Boosting Machine  0.97888  0.97900  \n",
      "Random Forest Classifier         0.97466  0.97482  \n",
      "Extreme Gradient Boosting        0.97038  0.97068  \n",
      "Gradient Boosting Classifier     0.97036  0.97058  \n",
      "\n",
      "--- Top 5 Models for [High_valence] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.99792  0.99964  0.99792  0.99796  0.99792   \n",
      "Gradient Boosting Classifier      0.99584  0.99956  0.99584  0.99592  0.99584   \n",
      "Random Forest Classifier          0.99584  1.00000  0.99584  0.99598  0.99582   \n",
      "Light Gradient Boosting Machine   0.99376  0.99940  0.99376  0.99394  0.99374   \n",
      "Ada Boost Classifier              0.99168  0.99876  0.99168  0.99174  0.99166   \n",
      "\n",
      "                                   Kappa      MCC  \n",
      "Model                                              \n",
      "CatBoost Classifier              0.99576  0.99580  \n",
      "Gradient Boosting Classifier     0.99152  0.99160  \n",
      "Random Forest Classifier         0.99148  0.99166  \n",
      "Light Gradient Boosting Machine  0.98724  0.98746  \n",
      "Ada Boost Classifier             0.98302  0.98312  \n",
      "\n",
      "--- Top 5 Models for [Low_arousal] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.99376  0.99744  0.99376  0.99394  0.99374   \n",
      "Light Gradient Boosting Machine   0.99376  0.99798  0.99376  0.99394  0.99374   \n",
      "Gradient Boosting Classifier      0.99168  0.99604  0.99168  0.99196  0.99164   \n",
      "Random Forest Classifier          0.99168  0.99678  0.99168  0.99204  0.99164   \n",
      "Ada Boost Classifier              0.98960  0.99648  0.98960  0.98992  0.98956   \n",
      "\n",
      "                                   Kappa      MCC  \n",
      "Model                                              \n",
      "CatBoost Classifier              0.98724  0.98746  \n",
      "Light Gradient Boosting Machine  0.98724  0.98746  \n",
      "Gradient Boosting Classifier     0.98296  0.98332  \n",
      "Random Forest Classifier         0.98296  0.98338  \n",
      "Ada Boost Classifier             0.97872  0.97912  \n",
      "\n",
      "--- Top 5 Models for [Low_valence] ---\n",
      "                              Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                        \n",
      "Decision Tree Classifier       0.98958  0.98968  0.98958  0.98966  0.98960   \n",
      "Gradient Boosting Classifier   0.98752  0.99912  0.98752  0.98796  0.98748   \n",
      "Extreme Gradient Boosting      0.98750  0.99894  0.98750  0.98816  0.98744   \n",
      "CatBoost Classifier            0.98544  0.99930  0.98544  0.98592  0.98540   \n",
      "Random Forest Classifier       0.98542  0.99872  0.98542  0.98566  0.98540   \n",
      "\n",
      "                                Kappa      MCC  \n",
      "Model                                           \n",
      "Decision Tree Classifier      0.97890  0.97894  \n",
      "Gradient Boosting Classifier  0.97448  0.97498  \n",
      "Extreme Gradient Boosting     0.97440  0.97516  \n",
      "CatBoost Classifier           0.97024  0.97078  \n",
      "Random Forest Classifier      0.97026  0.97054  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    loaded_results = load_all_results()\n",
    "    print(\"\\n--- Summary of Loaded Results ---\")\n",
    "    \n",
    "    if not loaded_results:\n",
    "        print(\"No result files were found.\")\n",
    "    else:\n",
    "        # Display the top 5 models for each loaded result\n",
    "        for name, result_df in loaded_results.items():\n",
    "            print(f\"\\n--- Top 5 Models for [{name}] ---\")\n",
    "            print(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94794762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etri-emotion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
