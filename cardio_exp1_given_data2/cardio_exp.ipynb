{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7b9478",
   "metadata": {},
   "source": [
    "# Description: \n",
    "##### This script implements a robust, manually controlled 5-fold cross-validation.\n",
    "* For each of the 5 predefined folds, it performs the following steps:\n",
    "    1. Trains all models on `train.csv`.\n",
    "    2. Selects the best models based on performance on `valid.csv`.\n",
    "    3. Retrains EACH model on the combined `train.csv` + `valid.csv`.\n",
    "    4. Evaluates EACH retrained model on `test.csv` to get its test performance.\n",
    "    \n",
    "    Finally, it averages the test performance for each model type across all 5 folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da93039",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "1. Make sure you have PyCaret and its dependencies installed.\n",
    "If not, uncomment the line below and run it once.\n",
    "> !pip install pycaret pandas\n",
    "\n",
    "2. Place this script in the same directory as your 90 CSV data files.\n",
    "\n",
    "3. Run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e18e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycaret.classification import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2746f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leechangmin/Desktop/Project/ETRI-Emotion/cardio_exp1_given_data2\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8689c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_strict_manual_5_fold_experiment():\n",
    "    \"\"\"\n",
    "    This function runs the experiment with a strict, manual 5-fold\n",
    "    process that honors the predefined train, validation, and test files.\n",
    "    \"\"\"\n",
    "    # --- Configuration ---\n",
    "    TARGET_COLUMN_NAME = 'label'\n",
    "    GROUPS = ['Total', 'High', 'Low']\n",
    "    VARIABLES = ['arousal', 'valence']\n",
    "    FOLDS = range(1, 6)\n",
    "    \n",
    "    final_averaged_results = {}\n",
    "\n",
    "    print(\"Starting PyCaret Classification with Manual 5-Fold Cross-Validation...\")\n",
    "\n",
    "    for group in GROUPS:\n",
    "        for variable in VARIABLES:\n",
    "            experiment_name = f\"{group}_{variable}\"\n",
    "            print(f\"\\n--- Starting Experiment: [{experiment_name}] ---\")\n",
    "\n",
    "            # This list will store the test performance DataFrames from each of the 5 folds.\n",
    "            all_folds_test_performance = []\n",
    "\n",
    "            for fold in FOLDS:\n",
    "                try:\n",
    "                    print(f\"  - Processing Fold {fold}...\")\n",
    "                    # 1. Load the strictly separated datasets\n",
    "                    train_df = pd.read_csv(f'./data/fold{fold}_{group}_{variable}_train.csv')\n",
    "                    valid_df = pd.read_csv(f'./data/fold{fold}_{group}_{variable}_valid.csv')\n",
    "                    test_df = pd.read_csv(f'./data/fold{fold}_{group}_{variable}_test.csv')\n",
    "\n",
    "                    # 2. Setup PyCaret to train on `train_df` and use `valid_df` as the hold-out\n",
    "                    #    set for initial model ranking.\n",
    "                    s = setup(data=train_df,\n",
    "                              test_data=valid_df,\n",
    "                              target=TARGET_COLUMN_NAME,\n",
    "                              index=False,\n",
    "                              session_id=123,\n",
    "                              verbose=False)\n",
    "\n",
    "                    # 3. Compare all models to get a performance grid on the validation set.\n",
    "                    compare_models(verbose=False)\n",
    "                    validation_grid = pull() # This contains all model types and their valid scores.\n",
    "\n",
    "                    # This list will store the test results for ALL models within THIS fold.\n",
    "                    current_fold_test_results = []\n",
    "                    \n",
    "                    # 4. Iterate through every model type, finalize it, and evaluate on the test set.\n",
    "                    print(f\"    > Evaluating all models on Fold {fold} test set...\")\n",
    "                    for model_id in validation_grid.index:\n",
    "                        # Create the model instance trained on train_df\n",
    "                        model = create_model(model_id, verbose=False)\n",
    "                        # Retrain on combined train_df + valid_df\n",
    "                        final_model = finalize_model(model)\n",
    "                        # Predict on the unseen test_df\n",
    "                        test_predictions = predict_model(final_model, data=test_df, verbose=False)\n",
    "                        # Extract and store the test metrics\n",
    "                        test_metrics = pull()\n",
    "                        # Manually add the 'Model' column since the metrics row doesn't have it.\n",
    "                        test_metrics['Model'] = validation_grid.loc[model_id, 'Model']\n",
    "                        \n",
    "                        current_fold_test_results.append(test_metrics)\n",
    "                    \n",
    "                    # Combine all model results for the current fold and add to the main list\n",
    "                    all_folds_test_performance.append(pd.concat(current_fold_test_results))\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"  - An error occurred in Fold {fold}: {e}\")\n",
    "\n",
    "            # After all 5 folds are processed, average the results\n",
    "            if all_folds_test_performance:\n",
    "                # Combine the performance DataFrames from all 5 folds\n",
    "                full_results_df = pd.concat(all_folds_test_performance)\n",
    "                \n",
    "                # Calculate the mean test performance for each model type across the 5 folds\n",
    "                numeric_cols = full_results_df.select_dtypes(include='number').columns\n",
    "                average_results = full_results_df.groupby('Model')[numeric_cols].mean().sort_values('Accuracy', ascending=False)\n",
    "                \n",
    "                final_averaged_results[experiment_name] = average_results\n",
    "                print(f\"  > Finished experiment [{experiment_name}]. Averaged test results from 5 folds.\")\n",
    "\n",
    "    # --- Print and Save Final Averaged Results ---\n",
    "    if final_averaged_results:\n",
    "        print(\"\\n--- Final Averaged Test Performance Across All Experiments ---\")\n",
    "        for name, result_df in final_averaged_results.items():\n",
    "            print(f\"\\n[{name}] - Top 5 Models by Averaged Test Performance:\")\n",
    "            print(result_df.head())\n",
    "            output_filename = f'results_{name}_manual_5fold_summary.csv'\n",
    "            result_df.to_csv(output_filename)\n",
    "            print(f\"> Results saved to '{output_filename}'\")\n",
    "    else:\n",
    "        print(\"\\nNo results were processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf772b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PyCaret Classification with Manual 5-Fold Cross-Validation...\n",
      "\n",
      "--- Starting Experiment: [Total_arousal] ---\n",
      "  - Processing Fold 1...\n",
      "    > Evaluating all models on Fold 1 test set...\n",
      "  - Processing Fold 2...\n",
      "    > Evaluating all models on Fold 2 test set...\n",
      "  - Processing Fold 3...\n",
      "    > Evaluating all models on Fold 3 test set...\n",
      "  - Processing Fold 4...\n",
      "    > Evaluating all models on Fold 4 test set...\n",
      "  - Processing Fold 5...\n",
      "    > Evaluating all models on Fold 5 test set...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dl/67z9yf312kv3dl30bp_61f4r0000gn/T/ipykernel_47463/4250039636.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This ensures the script runs when executed directly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrun_strict_manual_5_fold_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/dl/67z9yf312kv3dl30bp_61f4r0000gn/T/ipykernel_47463/515477838.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mfull_results_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_folds_test_performance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;31m# Calculate the mean test performance for each model type across the 5 folds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mnumeric_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_results_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'number'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0maverage_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_results_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumeric_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mfinal_averaged_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  > Finished experiment [{experiment_name}]. Averaged test results from 5 folds.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/etri-emotion/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   6940\u001b[0m             )\n\u001b[1;32m   6941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6942\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6944\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6946\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6947\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/etri-emotion/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1840\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1844\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Accuracy'"
     ]
    }
   ],
   "source": [
    "# This ensures the script runs when executed directly.\n",
    "if __name__ == '__main__':\n",
    "    run_strict_manual_5_fold_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4ca820",
   "metadata": {},
   "source": [
    "### Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e157c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_results():\n",
    "    \"\"\"\n",
    "    Read 'results_{group}_{variable}_classification_summary.csv' formatted files\n",
    "    and return a dictionary of DataFrames.\n",
    "    \"\"\"\n",
    "    # --- Configuration (can be adjusted as needed) ---\n",
    "    groups = ['Total', 'High', 'Low']\n",
    "    variables = ['arousal', 'valence']\n",
    "    \n",
    "    # dictionary to hold all results\n",
    "    all_results = {}\n",
    "    \n",
    "    print(\"Reading all result CSV files...\")\n",
    "\n",
    "    # Iterate through each group and variable to construct filenames\n",
    "    for group in groups:\n",
    "        for variable in variables:\n",
    "            # Construct the filename based on the group and variable\n",
    "            experiment_name = f\"{group}_{variable}\"\n",
    "            filename = f\"./res/results_{experiment_name}_classification_summary.csv\"\n",
    "            \n",
    "            try:\n",
    "                # CSV file into DataFrame\n",
    "                # index_col=0 to use the first column as index\n",
    "                df = pd.read_csv(filename, index_col=0)\n",
    "                \n",
    "                # Store the DataFrame in the dictionary with the experiment name as key\n",
    "                all_results[experiment_name] = df\n",
    "                print(f\"  - Successfully loaded: {filename}\")\n",
    "                \n",
    "            except FileNotFoundError:\n",
    "                print(f\"  - File not found, skipping: {filename}\")\n",
    "                \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c281b40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all result CSV files...\n",
      "  - Successfully loaded: ./res/results_Total_arousal_classification_summary.csv\n",
      "  - Successfully loaded: ./res/results_Total_valence_classification_summary.csv\n",
      "  - Successfully loaded: ./res/results_High_arousal_classification_summary.csv\n",
      "  - Successfully loaded: ./res/results_High_valence_classification_summary.csv\n",
      "  - Successfully loaded: ./res/results_Low_arousal_classification_summary.csv\n",
      "  - Successfully loaded: ./res/results_Low_valence_classification_summary.csv\n",
      "\n",
      "--- Summary of Loaded Results ---\n",
      "\n",
      "--- Top 5 Models for [Total_arousal] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "Gradient Boosting Classifier      0.95500  0.99220  0.95500  0.95646  0.95466   \n",
      "Random Forest Classifier          0.95374  0.99182  0.95374  0.95572  0.95346   \n",
      "CatBoost Classifier               0.95166  0.99230  0.95166  0.95406  0.95124   \n",
      "Ada Boost Classifier              0.94958  0.98554  0.94958  0.95152  0.94942   \n",
      "Light Gradient Boosting Machine   0.94958  0.99202  0.94958  0.95164  0.94924   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "Gradient Boosting Classifier     0.90404  0.90612    0.1682  \n",
      "Random Forest Classifier         0.90162  0.90414    0.0568  \n",
      "CatBoost Classifier              0.89680  0.89998    1.0144  \n",
      "Ada Boost Classifier             0.89340  0.89558    0.0422  \n",
      "Light Gradient Boosting Machine  0.89272  0.89540    0.3676  \n",
      "\n",
      "--- Top 5 Models for [Total_valence] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "Random Forest Classifier          0.95792  0.99502  0.95792  0.96048  0.95784   \n",
      "CatBoost Classifier               0.95374  0.99478  0.95374  0.95686  0.95362   \n",
      "Extreme Gradient Boosting         0.95126  0.99274  0.95126  0.95346  0.95116   \n",
      "Gradient Boosting Classifier      0.95126  0.99380  0.95126  0.95390  0.95116   \n",
      "Light Gradient Boosting Machine   0.94918  0.99282  0.94918  0.95206  0.94906   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "Random Forest Classifier         0.91582  0.91836    0.0490  \n",
      "CatBoost Classifier              0.90748  0.91060    1.0770  \n",
      "Extreme Gradient Boosting        0.90250  0.90474    0.0182  \n",
      "Gradient Boosting Classifier     0.90250  0.90516    0.1742  \n",
      "Light Gradient Boosting Machine  0.89832  0.90122    0.3398  \n",
      "\n",
      "--- Top 5 Models for [High_arousal] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.93630  0.98786  0.93630  0.94044  0.93592   \n",
      "Light Gradient Boosting Machine   0.93354  0.98480  0.93354  0.93744  0.93324   \n",
      "Gradient Boosting Classifier      0.93072  0.98448  0.93072  0.93522  0.93038   \n",
      "Random Forest Classifier          0.92830  0.98466  0.92830  0.93282  0.92778   \n",
      "Extreme Gradient Boosting         0.92732  0.98296  0.92732  0.93184  0.92694   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "CatBoost Classifier              0.86818  0.87260    1.1244  \n",
      "Light Gradient Boosting Machine  0.86292  0.86686    0.2550  \n",
      "Gradient Boosting Classifier     0.85698  0.86158    0.0982  \n",
      "Random Forest Classifier         0.85150  0.85638    0.0418  \n",
      "Extreme Gradient Boosting        0.84988  0.85454    0.0218  \n",
      "\n",
      "--- Top 5 Models for [High_valence] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "Random Forest Classifier          0.93614  0.98898  0.93614  0.94076  0.93578   \n",
      "CatBoost Classifier               0.93442  0.98640  0.93442  0.93894  0.93400   \n",
      "Gradient Boosting Classifier      0.93194  0.98556  0.93194  0.93596  0.93160   \n",
      "Light Gradient Boosting Machine   0.92890  0.98548  0.92890  0.93294  0.92856   \n",
      "Ada Boost Classifier              0.92714  0.98000  0.92714  0.93228  0.92672   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "Random Forest Classifier         0.87210  0.87672    0.0464  \n",
      "CatBoost Classifier              0.86860  0.87312    1.0884  \n",
      "Gradient Boosting Classifier     0.86376  0.86774    0.1056  \n",
      "Light Gradient Boosting Machine  0.85768  0.86168    0.2542  \n",
      "Ada Boost Classifier             0.85418  0.85924    0.0314  \n",
      "\n",
      "--- Top 5 Models for [Low_arousal] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "Gradient Boosting Classifier      0.95678  0.99182  0.95678  0.96176  0.95620   \n",
      "Light Gradient Boosting Machine   0.95630  0.99402  0.95630  0.96108  0.95558   \n",
      "Extreme Gradient Boosting         0.95484  0.99228  0.95484  0.95806  0.95438   \n",
      "Random Forest Classifier          0.95378  0.99246  0.95378  0.95916  0.95314   \n",
      "CatBoost Classifier               0.95254  0.99272  0.95254  0.95740  0.95172   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "Gradient Boosting Classifier     0.90680  0.91248    0.0814  \n",
      "Light Gradient Boosting Machine  0.90548  0.91122    0.2534  \n",
      "Extreme Gradient Boosting        0.90270  0.90660    0.0128  \n",
      "Random Forest Classifier         0.90068  0.90688    0.0396  \n",
      "CatBoost Classifier              0.89688  0.90302    0.9910  \n",
      "\n",
      "--- Top 5 Models for [Low_valence] ---\n",
      "                                 Accuracy      AUC   Recall    Prec.       F1  \\\n",
      "Model                                                                           \n",
      "CatBoost Classifier               0.97120  0.99646  0.97120  0.97450  0.97102   \n",
      "Gradient Boosting Classifier      0.96888  0.99644  0.96888  0.97150  0.96870   \n",
      "Light Gradient Boosting Machine   0.96784  0.99592  0.96784  0.97122  0.96760   \n",
      "Random Forest Classifier          0.96780  0.99474  0.96780  0.97228  0.96746   \n",
      "Ada Boost Classifier              0.96588  0.99362  0.96588  0.96886  0.96570   \n",
      "\n",
      "                                   Kappa      MCC  TT (Sec)  \n",
      "Model                                                        \n",
      "CatBoost Classifier              0.94230  0.94562    1.1904  \n",
      "Gradient Boosting Classifier     0.93770  0.94032    0.0900  \n",
      "Light Gradient Boosting Machine  0.93554  0.93892    0.2756  \n",
      "Random Forest Classifier         0.93562  0.94000    0.0452  \n",
      "Ada Boost Classifier             0.93166  0.93466    0.0328  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    loaded_results = load_all_results()\n",
    "    print(\"\\n--- Summary of Loaded Results ---\")\n",
    "    \n",
    "    if not loaded_results:\n",
    "        print(\"No result files were found.\")\n",
    "    else:\n",
    "        # Display the top 5 models for each loaded result\n",
    "        for name, result_df in loaded_results.items():\n",
    "            print(f\"\\n--- Top 5 Models for [{name}] ---\")\n",
    "            print(result_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etri-emotion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
